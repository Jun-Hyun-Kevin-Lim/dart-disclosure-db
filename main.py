import os
import re
import io
import json
import zipfile
import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

import gspread
from gspread.exceptions import WorksheetNotFound
from google.oauth2.service_account import Credentials

DART_API_KEY = os.getenv("DART_API_KEY", "").strip()
GOOGLE_CREDENTIALS_JSON = os.getenv("GOOGLE_CREDENTIALS_JSON", "").strip()
GOOGLE_SHEET_ID = os.getenv("GOOGLE_SHEET_ID", "").strip()

# ë‹¹ì¼ ê³µì‹œë§Œ ê°€ì ¸ì˜¤ê¸° (í…ŒìŠ¤íŠ¸ ì‹œ 1~3ìœ¼ë¡œ ëŠ˜ë ¤ë³´ì„¸ìš”)
LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "0"))
MAX_PAGES = int(os.getenv("MAX_PAGES", "5"))
PAGE_COUNT = int(os.getenv("PAGE_COUNT", "100"))
TIMEZONE = os.getenv("TIMEZONE", "Asia/Seoul")

# íƒ€ê²Ÿ ê³µì‹œëª… ì •ê·œì‹
TARGET_REPORT_RE = re.compile(r"(ìœ ìƒ\s*ì¦ì\s*ê²°ì •|ì „í™˜\s*ì‚¬ì±„\s*ê¶Œ\s*ë°œí–‰\s*ê²°ì •|êµí™˜\s*ì‚¬ì±„\s*ê¶Œ\s*ë°œí–‰\s*ê²°ì •)")

# ëŒ€í‘œë‹˜ì´ ì •ë¦¬í•´ì£¼ì‹  í•„ìˆ˜ URL ì ìš©
LIST_URL = "https://opendart.fss.or.kr/api/list.json"      # ëª©ë¡ì€ ë‹¤ë£¨ê¸° ì‰¬ìš´ jsonìœ¼ë¡œ
DOC_URL = "https://opendart.fss.or.kr/api/document.xml"    # ë¬¸ì„œëŠ” xml(zip)ë§Œ ì§€ì›

def require_env(name: str, value: str):
    if not value:
        raise RuntimeError(f"Missing required env var: {name}")

def clean_str(x) -> str:
    if x is None: return ""
    s = str(x).strip()
    return "" if s.lower() == "nan" else s

def normalize_ws(s: str) -> str:
    s = clean_str(s)
    return re.sub(r"\s+", " ", s).strip()

def extract_number(s: str):
    s = clean_str(s)
    if not s: return ""
    t = re.sub(r"[^\d\-\.]", "", s)
    if t in ("", "-", "."): return ""
    try:
        return str(int(float(t)) if "." in t else int(t))
    except:
        return ""

def get_gsheet_client():
    require_env("GOOGLE_CREDENTIALS_JSON", GOOGLE_CREDENTIALS_JSON)
    info = json.loads(GOOGLE_CREDENTIALS_JSON)
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_info(info, scopes=scopes)
    return gspread.authorize(creds)

def get_or_create_worksheet(sh, title: str):
    try:
        ws = sh.worksheet(title)
    except WorksheetNotFound:
        ws = sh.add_worksheet(title=title, rows="1000", cols="20")
    return ws

def ensure_header(ws):
    header = [
        "ì ‘ìˆ˜ë²ˆí˜¸", "íšŒì‚¬ëª…", "ìƒì¥ì‹œì¥", "ë³´ê³ ì„œëª…", "ì´ì‚¬íšŒê²°ì˜ì¼", "ë°œí–‰ë°©ì‹", "ë°œí–‰ìƒí’ˆ",
        "ë°œí–‰ìˆ˜ëŸ‰(ì£¼/ê¶Œë©´)", "ë°œí–‰(ì „í™˜/êµí™˜)ê°€(ì›)", "ê¸°ì¤€ì£¼ê°€(ì›)", "ì¡°ë‹¬ê¸ˆì•¡(ì–µì›)", "í• ì¸/í• ì¦ë¥ ",
        "ì¦ìì „ ì£¼ì‹ìˆ˜", "ì¦ìë¹„ìœ¨(%)", "ì²­ì•½ì¼", "ë‚©ì…ì¼", "ìê¸ˆìš©ë„", "íˆ¬ìì/ëŒ€ìƒì", "ì£¼ê´€ì‚¬"
    ]
    if not ws.row_values(1):
        ws.append_row(header, value_input_option="USER_ENTERED")

def get_processed_rcept_set(ws):
    col = ws.col_values(1)
    if not col or col[0].strip() == "ì ‘ìˆ˜ë²ˆí˜¸":
        return set(x.strip() for x in col[1:] if x.strip())
    return set(x.strip() for x in col if x.strip())

def dart_list_json(bgn_de: str, end_de: str):
    """list.jsonì„ í™œìš©í•˜ì—¬ ê³µì‹œ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    require_env("DART_API_KEY", DART_API_KEY)
    results = []
    page_no = 1
    while page_no <= MAX_PAGES:
        params = {
            "crtfc_key": DART_API_KEY, "bgn_de": bgn_de, "end_de": end_de,
            "sort": "date", "sort_mth": "desc",
            "page_no": str(page_no), "page_count": str(PAGE_COUNT),
        }
        r = requests.get(LIST_URL, params=params, timeout=30)
        data = r.json()
        
        if data.get("status") != "000": break
        
        results.extend(data.get("list", []))
        
        total_page = data.get("total_page", 1)
        if page_no >= total_page: break
        page_no += 1
    return results

def get_document_html(rcept_no: str) -> str:
    """document.xmlì„ í˜¸ì¶œí•´ ZIP íŒŒì¼ì„ ë‹¤ìš´ë°›ê³  ë©”ì¸ HTMLì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    params = {"crtfc_key": DART_API_KEY, "rcept_no": rcept_no}
    try:
        r = requests.get(DOC_URL, params=params, timeout=60)
        zf = zipfile.ZipFile(io.BytesIO(r.content))
        # HTML íŒŒì¼ ì°¾ê¸° (ë³´í†µ ì—¬ëŸ¬ ê°œê°€ ìˆì§€ë§Œ ê°€ì¥ ìš©ëŸ‰ì´ í° ê²ƒì´ ë³¸ë¬¸ì…ë‹ˆë‹¤)
        html_files = [n for n in zf.namelist() if n.lower().endswith((".html", ".htm"))]
        if not html_files: return ""
        largest_html = max(html_files, key=lambda n: zf.getinfo(n).file_size)
        raw = zf.read(largest_html)
        
        # ì¸ì½”ë”© ì²˜ë¦¬
        for enc in ("utf-8", "cp949", "euc-kr"):
            try: return raw.decode(enc)
            except: continue
        return raw.decode("utf-8", errors="ignore")
    except Exception as e:
        print(f"HTML ì¶”ì¶œ ì‹¤íŒ¨ ({rcept_no}): {e}")
        return ""

def parse_html_content(html: str, report_type: str) -> dict:
    """ë‹¤ìš´ë°›ì€ HTML í‘œ(Table)ì™€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ 19ê°œ í•„ë“œê°’ì„ ê¸ì–´ëƒ…ë‹ˆë‹¤."""
    out = {
        "board_date": "", "method": "", "qty": "", "issue_price": "", 
        "base_price": "", "total_amount": "", "discount": "", "pre_qty": "", 
        "sub_date": "", "pay_date": "", "purpose": "", "investor": "", "underwriter": ""
    }
    
    if not html: return out
    
    soup = BeautifulSoup(html, "lxml")
    text = soup.get_text(" ").replace("\n", " ")

    # 1. ì •ê·œì‹ í…ìŠ¤íŠ¸ íŒŒì‹± (íˆ¬ìì, ì£¼ê´€ì‚¬, ì´ì‚¬íšŒê²°ì˜ì¼ ë“±)
    investor_match = re.search(r"(ë°°ì •ëŒ€ìƒì|ì œ3ì\s*ë°°ì •ëŒ€ìƒì|íˆ¬ìì)\s*[:ï¼š]?\s*([ê°€-í£a-zA-Z0-9\sãˆœ]+)", text)
    if investor_match: out["investor"] = investor_match.group(2)[:30].strip()
    
    underwriter_match = re.search(r"(ì£¼ê´€íšŒì‚¬|ëŒ€í‘œì£¼ê´€íšŒì‚¬|ì¸ìˆ˜íšŒì‚¬)\s*[:ï¼š]?\s*([ê°€-í£a-zA-Z0-9\sãˆœ]+ì¦ê¶Œ)", text)
    if underwriter_match: out["underwriter"] = underwriter_match.group(2)[:30].strip()
    
    board_match = re.search(r"ì´ì‚¬íšŒ\s*ê²°ì˜ì¼.*?(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼", text)
    if board_match:
        out["board_date"] = f"{board_match.group(1)}-{int(board_match.group(2)):02d}-{int(board_match.group(3)):02d}"

    # 2. Pandasë¥¼ ì´ìš©í•œ í‘œ(Table) ë°ì´í„° íŒŒì‹±
    try:
        dfs = pd.read_html(io.StringIO(html))
        for df in dfs:
            df = df.fillna("").astype(str)
            for _, row in df.iterrows():
                row_vals = [normalize_ws(v) for v in row.tolist()]
                row_str = " ".join(row_vals)
                
                # ìê¸ˆì¡°ë‹¬ ëª©ì  íŒŒì‹± (ì–µì› ë‹¨ìœ„ ë³€í™˜)
                if "ìê¸ˆì¡°ë‹¬ì˜ ëª©ì " in row_str or "ì‹œì„¤ìê¸ˆ" in row_str or "ìš´ì˜ìê¸ˆ" in row_str:
                    purposes = []
                    total = 0
                    for k, label in [("ì‹œì„¤ìê¸ˆ", "ì‹œì„¤"), ("ìš´ì˜ìê¸ˆ", "ìš´ì˜"), ("ì˜ì—…ì–‘ìˆ˜ìê¸ˆ", "ì˜ì—…ì–‘ìˆ˜"), 
                                     ("ì±„ë¬´ìƒí™˜ìê¸ˆ", "ì±„ë¬´ìƒí™˜"), ("íƒ€ë²•ì¸ ì¦ê¶Œ ì·¨ë“ìê¸ˆ", "íƒ€ë²•ì¸ì¦ê¶Œì·¨ë“"), ("ê¸°íƒ€ìê¸ˆ", "ê¸°íƒ€")]:
                        for i, cell in enumerate(row_vals):
                            if k in cell and i + 1 < len(row_vals):
                                val = extract_number(row_vals[i+1])
                                if val:
                                    eok = round(int(val) / 100_000_000, 2)
                                    if eok > 0:
                                        purposes.append(f"{label}:{eok}ì–µ")
                                        total += int(val)
                    if purposes: out["purpose"] = ", ".join(purposes)
                    if total > 0 and not out["total_amount"]: out["total_amount"] = str(round(total / 100_000_000, 2))

                # ê¸°íƒ€ ì£¼ìš” í•­ëª© ì¶”ì¶œ ë¡œì§
                for i, cell in enumerate(row_vals):
                    if not cell: continue
                    next_val = row_vals[i+1] if i + 1 < len(row_vals) else ""
                    
                    if any(x in cell for x in ["ì¦ìë°©ì‹", "ì‚¬ì±„ë°œí–‰ë°©ë²•"]) and not out["method"]:
                        out["method"] = next_val
                    elif any(x in cell for x in ["ì‹ ì£¼ë°œí–‰ê°€ì•¡", "ì „í™˜ê°€ì•¡", "êµí™˜ê°€ì•¡"]) and not out["issue_price"]:
                        out["issue_price"] = extract_number(next_val)
                    elif "ê¸°ì¤€ì£¼ê°€" in cell and not out["base_price"]:
                        out["base_price"] = extract_number(next_val)
                    elif any(x in cell for x in ["í• ì¸ìœ¨", "í• ì¦ìœ¨"]) and not out["discount"]:
                        out["discount"] = next_val
                    elif any(x in cell for x in ["ì²­ì•½ê¸°ì¼", "ì²­ì•½ì‹œì‘ì¼"]) and not out["sub_date"]:
                        out["sub_date"] = next_val.replace("ë…„", "-").replace("ì›”", "-").replace("ì¼", "").replace(" ", "")
                    elif "ë‚©ì…ê¸°ì¼" in cell and not out["pay_date"]:
                        out["pay_date"] = next_val.replace("ë…„", "-").replace("ì›”", "-").replace("ì¼", "").replace(" ", "")
                    elif any(x in cell for x in ["ì‚¬ì±„ì˜ ê¶Œë©´ì´ì•¡", "ì‹ ì£¼ì˜ ìˆ˜"]) and not out["qty"]:
                        out["qty"] = extract_number(next_val)
                    elif "ì¦ìì „ ë°œí–‰ì£¼ì‹ì´ìˆ˜" in cell and not out["pre_qty"]:
                        out["pre_qty"] = extract_number(next_val)
                        
    except Exception as e:
        print(f"í‘œ ë¶„ì„ ì¤‘ ì—ëŸ¬ (í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œë§Œ ì§„í–‰): {e}")

    # ì¦ìë¹„ìœ¨ ê³„ì‚°
    if out["qty"] and out["pre_qty"] and report_type == "ìœ ìƒì¦ì":
        try:
            out["ratio"] = str(round((int(out["qty"]) / int(out["pre_qty"])) * 100, 2))
        except:
            out["ratio"] = ""
    else:
        out["ratio"] = ""

    return out

def build_row(list_item: dict, report_type: str, parsed: dict):
    rcept_no = list_item.get("rcept_no", "")
    corp_name = list_item.get("corp_name", "")
    market = list_item.get("corp_cls", "")
    market = {"Y": "KOSPI", "K": "KOSDAQ", "N": "KONEX", "E": "ETC"}.get(market, market)
    report_nm = list_item.get("report_nm", "")

    return [
        rcept_no, corp_name, market, report_nm,
        parsed["board_date"], parsed["method"], report_type,
        parsed["qty"], parsed["issue_price"], parsed["base_price"], parsed["total_amount"], parsed["discount"],
        parsed["pre_qty"], parsed.get("ratio", ""), parsed["sub_date"], parsed["pay_date"],
        parsed["purpose"], parsed["investor"], parsed["underwriter"]
    ]

def main():
    require_env("DART_API_KEY", DART_API_KEY)
    require_env("GOOGLE_SHEET_ID", GOOGLE_SHEET_ID)

    tz = ZoneInfo(TIMEZONE)
    today = datetime.now(tz).date()
    bgn = today - timedelta(days=LOOKBACK_DAYS)
    bgn_de = bgn.strftime("%Y%m%d")
    end_de = today.strftime("%Y%m%d")

    gc = get_gsheet_client()
    sh = gc.open_by_key(GOOGLE_SHEET_ID)

    sheet_names = ["ìœ ìƒì¦ì", "ì „í™˜ì‚¬ì±„", "êµí™˜ì‚¬ì±„"]
    worksheets = {}
    processed_rcepts = {}

    for name in sheet_names:
        ws = get_or_create_worksheet(sh, name)
        ensure_header(ws)
        worksheets[name] = ws
        processed_rcepts[name] = get_processed_rcept_set(ws)

    # 1. list.jsonìœ¼ë¡œ ì „ì²´ ê³µì‹œ ê²€ìƒ‰
    items = dart_list_json(bgn_de=bgn_de, end_de=end_de)
    print(f"ğŸ“‹ DART ëª©ë¡ ê²€ìƒ‰(list.json) ì™„ë£Œ: ì´ {len(items)}ê±´ í™•ì¸ë¨.")
    
    rows_to_append = {"ìœ ìƒì¦ì": [], "ì „í™˜ì‚¬ì±„": [], "êµí™˜ì‚¬ì±„": []}

    for it in items:
        report_nm = it.get("report_nm", "")
        
        report_type = ""
        if "ìœ ìƒ" in report_nm and "ê²°ì •" in report_nm: report_type = "ìœ ìƒì¦ì"
        elif "ì „í™˜ì‚¬ì±„" in report_nm and "ê²°ì •" in report_nm: report_type = "ì „í™˜ì‚¬ì±„"
        elif "êµí™˜ì‚¬ì±„" in report_nm and "ê²°ì •" in report_nm: report_type = "êµí™˜ì‚¬ì±„"
        else: continue 

        rcept_no = it.get("rcept_no")
        corp_name = it.get("corp_name", "ì•Œìˆ˜ì—†ìŒ")
        print(f"\nğŸ” íƒ€ê²Ÿ ê³µì‹œ ë°œê²¬: [{corp_name}] {report_nm}")

        if rcept_no in processed_rcepts[report_type]:
            print("   -> ğŸš« ì´ë¯¸ ê¸°ë¡ëœ ê³µì‹œì…ë‹ˆë‹¤. íŒ¨ìŠ¤.")
            continue
            
        # 2. document.xmlë¡œ ì›ë³¸ HTML ì‹¤ì‹œê°„ ë‹¤ìš´ë¡œë“œ ë° ë¶„ì„ (ì§€ì—° ì—†ìŒ!)
        print("   -> ğŸ“¥ ì›ë³¸ HTML ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ë° ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        html_content = get_document_html(rcept_no)
        parsed_data = parse_html_content(html_content, report_type)
        
        row = build_row(it, report_type, parsed_data)
        rows_to_append[report_type].append(row)
        print("   -> âœ… ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ ë° ì‹œíŠ¸ ëŒ€ê¸°ì—´ ì¶”ê°€.")

    print("\n[ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ê²°ê³¼]")
    for name in sheet_names:
        if rows_to_append[name]:
            worksheets[name].append_rows(rows_to_append[name], value_input_option="USER_ENTERED")
            print(f"âœ… {name} ì‹œíŠ¸: {len(rows_to_append[name])}ê±´ ì¶”ê°€ ì™„ë£Œ.")
        else:
            print(f"âœ… {name} ì‹œíŠ¸: ìƒˆë¡œ ì¶”ê°€í•  ë‚´ìš© ì—†ìŒ.")

if __name__ == "__main__":
    main()
