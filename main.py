import os
import re
import io
import json
import zipfile
import requests
import pandas as pd
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from zoneinfo import ZoneInfo

import gspread
from gspread.exceptions import WorksheetNotFound
from google.oauth2.service_account import Credentials

DART_API_KEY = os.getenv("DART_API_KEY", "").strip()
GOOGLE_CREDENTIALS_JSON = os.getenv("GOOGLE_CREDENTIALS_JSON", "").strip()
GOOGLE_SHEET_ID = os.getenv("GOOGLE_SHEET_ID", "").strip()

# ë‹¹ì¼ ê³µì‹œ ê¸°ì¤€ (ê³¼ê±° ë°ì´í„° í…ŒìŠ¤íŠ¸ ì‹œ 1~3 ë“± ìˆ«ìë¡œ ë³€ê²½ ê°€ëŠ¥)
LOOKBACK_DAYS = int(os.getenv("LOOKBACK_DAYS", "0"))
MAX_PAGES = int(os.getenv("MAX_PAGES", "5"))
PAGE_COUNT = int(os.getenv("PAGE_COUNT", "100"))
TIMEZONE = os.getenv("TIMEZONE", "Asia/Seoul")

# 1. ëŒ€í‘œë‹˜ì´ ê°•ì¡°í•˜ì‹  ê°€ì¥ ì¤‘ìš”í•œ ì „ìš© JSON API ì—”ë“œí¬ì¸íŠ¸!
API_URLS = {
    "ìœ ìƒì¦ì": "https://opendart.fss.or.kr/api/piicDecsn.json",
    "ì „í™˜ì‚¬ì±„": "https://opendart.fss.or.kr/api/cvbdIsDecsn.json",
    "êµí™˜ì‚¬ì±„": "https://opendart.fss.or.kr/api/exbdIsDecsn.json"
}

# 2. ì‹¤ì‹œê°„ ëª©ë¡ ê²€ìƒ‰(JSON) ë° ë³´ì¡° ì›ë³¸ ë¬¸ì„œ(XML/HTML) ì—”ë“œí¬ì¸íŠ¸
LIST_URL = "https://opendart.fss.or.kr/api/list.json"
DOC_URL = "https://opendart.fss.or.kr/api/document.xml"

def require_env(name: str, value: str):
    if not value:
        raise RuntimeError(f"Missing required env var: {name}")

def clean_str(x) -> str:
    if x is None: return ""
    s = str(x).strip()
    return "" if s.lower() == "nan" else s

def parse_int_maybe(s: str):
    s = clean_str(s)
    if not s: return None
    t = re.sub(r"[^\d\-\.]", "", s)
    if t in ("", "-", "."): return None
    try:
        return int(float(t)) if "." in t else int(t)
    except:
        return None

def amount_won_to_eok(won: int):
    """ì› ë‹¨ìœ„ë¥¼ ì–µì› ë‹¨ìœ„ë¡œ ë³€í™˜ (ì†Œìˆ˜ì  2ìë¦¬)"""
    if not won: return ""
    return round(won / 100_000_000, 2)

def get_gsheet_client():
    require_env("GOOGLE_CREDENTIALS_JSON", GOOGLE_CREDENTIALS_JSON)
    info = json.loads(GOOGLE_CREDENTIALS_JSON)
    scopes = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]
    creds = Credentials.from_service_account_info(info, scopes=scopes)
    return gspread.authorize(creds)

def get_or_create_worksheet(sh, title: str):
    try:
        ws = sh.worksheet(title)
    except WorksheetNotFound:
        print(f"[{title}] ì‹œíŠ¸ê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        ws = sh.add_worksheet(title=title, rows="1000", cols="20")
    return ws

def ensure_header(ws):
    header = [
        "ì ‘ìˆ˜ë²ˆí˜¸", "íšŒì‚¬ëª…", "ìƒì¥ì‹œì¥", "ë³´ê³ ì„œëª…", "ì´ì‚¬íšŒê²°ì˜ì¼", "ë°œí–‰ë°©ì‹", "ë°œí–‰ìƒí’ˆ",
        "ë°œí–‰ìˆ˜ëŸ‰(ì£¼/ê¶Œë©´)", "ë°œí–‰(ì „í™˜/êµí™˜)ê°€(ì›)", "ê¸°ì¤€ì£¼ê°€(ì›)", "ì¡°ë‹¬ê¸ˆì•¡(ì–µì›)", "í• ì¸/í• ì¦ë¥ ",
        "ì¦ìì „ ì£¼ì‹ìˆ˜", "ì¦ìë¹„ìœ¨(%)", "ì²­ì•½ì¼", "ë‚©ì…ì¼", "ìê¸ˆìš©ë„", "íˆ¬ìì/ëŒ€ìƒì", "ì£¼ê´€ì‚¬"
    ]
    if not ws.row_values(1):
        ws.append_row(header, value_input_option="USER_ENTERED")

def get_processed_rcept_set(ws):
    col = ws.col_values(1)
    if not col or col[0].strip() == "ì ‘ìˆ˜ë²ˆí˜¸":
        return set(x.strip() for x in col[1:] if x.strip())
    return set(x.strip() for x in col if x.strip())

def dart_list_json(bgn_de: str, end_de: str):
    """list.jsonì„ í™œìš©í•˜ì—¬ ë‹¹ì¼ ê³µì‹œ ëª©ë¡ì„ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    require_env("DART_API_KEY", DART_API_KEY)
    results = []
    page_no = 1
    while page_no <= MAX_PAGES:
        params = {
            "crtfc_key": DART_API_KEY, "bgn_de": bgn_de, "end_de": end_de,
            "sort": "date", "sort_mth": "desc",
            "page_no": str(page_no), "page_count": str(PAGE_COUNT),
        }
        r = requests.get(LIST_URL, params=params, timeout=30)
        data = r.json()
        
        if data.get("status") != "000": break
        results.extend(data.get("list", []))
        
        total_page = data.get("total_page", 1)
        if page_no >= total_page: break
        page_no += 1
    return results

def get_structured_json_data(corp_code: str, rcept_no: str, report_type: str):
    """ëŒ€í‘œë‹˜ì´ ì§€ì •í•œ 3ê°œì˜ ì „ìš© JSON APIì—ì„œ ì •í™•í•œ í•µì‹¬ ìˆ˜ì¹˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    url = API_URLS.get(report_type)
    if not url: return {}

    params = {"crtfc_key": DART_API_KEY, "corp_code": corp_code}
    try:
        r = requests.get(url, params=params, timeout=30)
        data = r.json()
        if data.get("status") == "000":
            for row in data.get("list", []):
                if str(row.get("rcept_no", "")).strip() == str(rcept_no).strip():
                    return row
    except Exception as e:
        print(f"JSON API í˜¸ì¶œ ì—ëŸ¬: {e}")
    return {}

def extract_purpose(data: dict) -> str:
    """ìê¸ˆì¡°ë‹¬ ëª©ì ì„ íŒŒì‹±í•˜ì—¬ ì–µì› ë‹¨ìœ„ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤."""
    purpose_parts = []
    labels = [
        ("fdpp_fclt", "ì‹œì„¤"), ("fdpp_op", "ìš´ì˜"), ("fdpp_bsninh", "ì˜ì—…ì–‘ìˆ˜"),
        ("fdpp_dtrp", "ì±„ë¬´ìƒí™˜"), ("fdpp_ocsa", "íƒ€ë²•ì¸ì¦ê¶Œì·¨ë“"), ("fdpp_etc", "ê¸°íƒ€")
    ]
    for key, label in labels:
        v = parse_int_maybe(data.get(key))
        if v and v > 0:
            purpose_parts.append(f"{label}:{amount_won_to_eok(v)}ì–µ")
    return ", ".join(purpose_parts)

def parse_html_for_investor_and_underwriter(rcept_no: str) -> dict:
    """JSON APIì—ì„œ ì œê³µí•˜ì§€ ì•ŠëŠ” 'íˆ¬ìì'ì™€ 'ì£¼ê´€ì‚¬' ì •ë³´ë§Œ ì›ë³¸ HTMLì—ì„œ ì•ˆì „í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    params = {"crtfc_key": DART_API_KEY, "rcept_no": rcept_no}
    out = {"íˆ¬ìì": "", "ì£¼ê´€ì‚¬": ""}
    try:
        r = requests.get(DOC_URL, params=params, timeout=60)
        zf = zipfile.ZipFile(io.BytesIO(r.content))
        html_file = next(n for n in zf.namelist() if n.lower().endswith((".html", ".htm")))
        html = zf.read(html_file).decode("utf-8", errors="ignore")
        
        soup = BeautifulSoup(html, "lxml")
        text = soup.get_text(" ").replace("\n", " ")
        
        investor_match = re.search(r"(ë°°ì •ëŒ€ìƒì|ì œ3ì\s*ë°°ì •ëŒ€ìƒì|íˆ¬ìì)\s*[:ï¼š]?\s*([ê°€-í£a-zA-Z0-9\sãˆœ]+)", text)
        if investor_match: out["íˆ¬ìì"] = investor_match.group(2)[:30].strip()
        
        underwriter_match = re.search(r"(ì£¼ê´€íšŒì‚¬|ëŒ€í‘œì£¼ê´€íšŒì‚¬|ì¸ìˆ˜íšŒì‚¬)\s*[:ï¼š]?\s*([ê°€-í£a-zA-Z0-9\sãˆœ]+ì¦ê¶Œ)", text)
        if underwriter_match: out["ì£¼ê´€ì‚¬"] = underwriter_match.group(2)[:30].strip()
    except:
        pass
    return out

def build_row(list_item: dict, report_type: str, data: dict, doc_data: dict):
    """ì „ìš© JSON APIì˜ ì •í™•í•œ ë°ì´í„°ë¥¼ êµ¬ê¸€ ì‹œíŠ¸ 19ê°œ ì—´(Column)ì— ì™„ë²½í•˜ê²Œ 1:1 ë§¤í•‘í•©ë‹ˆë‹¤."""
    rcept_no = list_item.get("rcept_no", "")
    corp_name = list_item.get("corp_name", "")
    market = list_item.get("corp_cls", "")
    market = {"Y": "KOSPI", "K": "KOSDAQ", "N": "KONEX", "E": "ETC"}.get(market, market)
    report_nm = list_item.get("report_nm", "")
    
    board_date = data.get("bddd", "") 
    purpose = extract_purpose(data) 
    investor = doc_data.get("íˆ¬ìì", "")
    underwriter = doc_data.get("ì£¼ê´€ì‚¬", "")

    if report_type == "ìœ ìƒì¦ì":
        method = data.get("ic_mthn", "")
        product = "ìœ ìƒì¦ì"
        qty = (parse_int_maybe(data.get("nstk_ostk_cnt")) or 0) + (parse_int_maybe(data.get("nstk_estk_cnt")) or 0)
        issue_price = data.get("tisstk_prc", "") 
        base_price = data.get("bsstk_prc", "") 
        total_amount = parse_int_maybe(data.get("fdpp_totam")) 
        discount = data.get("drt", "") 
        sub_date = data.get("sbscpn_bgd", "") 
        pay_date = data.get("pymdt", "") 
        
        pre_qty = (parse_int_maybe(data.get("bfic_tisstk_ostk")) or 0) + (parse_int_maybe(data.get("bfic_tisstk_estk")) or 0)
        ratio = round((qty / pre_qty) * 100, 2) if pre_qty and qty else ""
        
    elif report_type == "ì „í™˜ì‚¬ì±„":
        # ì „í™˜ì‚¬ì±„ê¶Œ ì „ìš© í‚¤ê°’ ì ìš©
        method = data.get("fnd_mthd", data.get("cvbd_is_mthd", ""))
        product = "ì „í™˜ì‚¬ì±„"
        qty = data.get("bnd_fac_totam", "") 
        issue_price = data.get("cnv_prc", "") 
        base_price = "" 
        total_amount = parse_int_maybe(data.get("bnd_fac_totam"))
        discount = ""
        sub_date = data.get("sbscpn_bgd", "")
        pay_date = data.get("sbpmcb_pymdt", "") 
        pre_qty, ratio = "", ""
        
    elif report_type == "êµí™˜ì‚¬ì±„":
        # êµí™˜ì‚¬ì±„ê¶Œ ì „ìš© í‚¤ê°’ ì ìš©
        method = data.get("fnd_mthd", data.get("excbnd_is_mthd", ""))
        product = "êµí™˜ì‚¬ì±„"
        qty = data.get("bnd_fac_totam", "") 
        issue_price = data.get("exch_prc", "") 
        base_price = ""
        total_amount = parse_int_maybe(data.get("bnd_fac_totam"))
        discount = ""
        sub_date = data.get("sbscpn_bgd", "")
        pay_date = data.get("sbpmcb_pymdt", "")
        pre_qty, ratio = "", ""

    amount_eok = amount_won_to_eok(total_amount) if total_amount else ""

    # 19ê°œ ì»¬ëŸ¼ ìˆœì„œ ê³ ì •!
    return [
        rcept_no, corp_name, market, report_nm, board_date, method, product,
        str(qty), str(issue_price), str(base_price), str(amount_eok), discount,
        str(pre_qty), str(ratio), sub_date, pay_date, purpose, investor, underwriter
    ]

def main():
    require_env("DART_API_KEY", DART_API_KEY)
    require_env("GOOGLE_SHEET_ID", GOOGLE_SHEET_ID)

    tz = ZoneInfo(TIMEZONE)
    today = datetime.now(tz).date()
    bgn = today - timedelta(days=LOOKBACK_DAYS)
    bgn_de = bgn.strftime("%Y%m%d")
    end_de = today.strftime("%Y%m%d")

    gc = get_gsheet_client()
    sh = gc.open_by_key(GOOGLE_SHEET_ID)

    sheet_names = ["ìœ ìƒì¦ì", "ì „í™˜ì‚¬ì±„", "êµí™˜ì‚¬ì±„"]
    worksheets = {}
    processed_rcepts = {}

    for name in sheet_names:
        ws = get_or_create_worksheet(sh, name)
        ensure_header(ws)
        worksheets[name] = ws
        processed_rcepts[name] = get_processed_rcept_set(ws)

    # ì „ì²´ ê³µì‹œ ë¦¬ìŠ¤íŠ¸ í˜¸ì¶œ
    items = dart_list_json(bgn_de=bgn_de, end_de=end_de)
    print(f"ğŸ“‹ ê³µì‹œ ëª©ë¡ ê²€ìƒ‰ ì™„ë£Œ: {bgn_de} ~ {end_de} ê¸°ê°„ ì´ {len(items)}ê±´")
    
    rows_to_append = {"ìœ ìƒì¦ì": [], "ì „í™˜ì‚¬ì±„": [], "êµí™˜ì‚¬ì±„": []}

    for it in items:
        report_nm = it.get("report_nm", "")
        
        report_type = ""
        if "ìœ ìƒ" in report_nm and "ê²°ì •" in report_nm: report_type = "ìœ ìƒì¦ì"
        elif "ì „í™˜ì‚¬ì±„" in report_nm and "ê²°ì •" in report_nm: report_type = "ì „í™˜ì‚¬ì±„"
        elif "êµí™˜ì‚¬ì±„" in report_nm and "ê²°ì •" in report_nm: report_type = "êµí™˜ì‚¬ì±„"
        else: continue 

        rcept_no = it.get("rcept_no")
        corp_name = it.get("corp_name", "ì•Œìˆ˜ì—†ìŒ")
        
        print(f"\nğŸ” íƒ€ê²Ÿ ê³µì‹œ ë°œê²¬: [{corp_name}] {report_nm} (ì ‘ìˆ˜ë²ˆí˜¸: {rcept_no})")

        if rcept_no in processed_rcepts[report_type]:
            print(f"   -> ğŸš« ì´ë¯¸ êµ¬ê¸€ ì‹œíŠ¸ì— ë“±ë¡ëœ ê³µì‹œì…ë‹ˆë‹¤. íŒ¨ìŠ¤.")
            continue
            
        corp_code = it.get("corp_code")
        
        # ğŸ’¡ ëŒ€í‘œë‹˜ì´ ê°•ì¡°í•˜ì‹  í•µì‹¬! ì „ìš© JSON APIì—ì„œ ì •í™•í•œ ì¬ë¬´ ë°ì´í„°ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        structured_data = get_structured_json_data(corp_code, rcept_no, report_type)
        
        if structured_data:
            # ìˆ˜ì¹˜ ë°ì´í„°ê°€ ì¡´ì¬í•˜ë©´ ë³´ì¡° ì •ë³´(íˆ¬ìì/ì£¼ê´€ì‚¬)ë¥¼ ìœ„í•´ HTMLì„ ê¸ì–´ì˜µë‹ˆë‹¤.
            doc_data = parse_html_for_investor_and_underwriter(rcept_no)
            row = build_row(it, report_type, structured_data, doc_data)
            rows_to_append[report_type].append(row)
            print(f"   -> âœ… ë°ì´í„° 100% ì™„ë²½ ë§¤í•‘. ì‹œíŠ¸ ëŒ€ê¸°ì—´ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.")
        else:
            # ê¸ˆê°ì› ì„œë²„ì—ì„œ JSON ë°ì´í„° ë³€í™˜ì´ ì§€ì—°ë˜ê³  ìˆì„ ê²½ìš°
            print(f"   -> â³ ê¸ˆê°ì› ì „ìš© JSON API ì—…ë°ì´íŠ¸ ì§€ì—° ì¤‘. ì—‰ëš±í•œ ë°ì´í„°ë¥¼ ë„£ì§€ ì•Šê¸° ìœ„í•´ ë‹¤ìŒ ì‹¤í–‰ ì‹œ ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.")

    print("\n[ì‹œíŠ¸ ìµœì¢… ì—…ë°ì´íŠ¸ ê²°ê³¼]")
    for name in sheet_names:
        if rows_to_append[name]:
            worksheets[name].append_rows(rows_to_append[name], value_input_option="USER_ENTERED")
            print(f"âœ… {name} ì‹œíŠ¸: {len(rows_to_append[name])}ê±´ ì¶”ê°€ ì™„ë£Œ.")
        else:
            print(f"âœ… {name} ì‹œíŠ¸: ìƒˆë¡œ ì¶”ê°€í•  ë‚´ìš© ì—†ìŒ.")

if __name__ == "__main__":
    main()
