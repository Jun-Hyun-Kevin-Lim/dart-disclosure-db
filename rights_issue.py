import os
import json
import gspread
import pandas as pd
import requests
import zipfile
import io
import re
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

# 1. GitHub Secrets ì„¤ì •ê°’
dart_key = os.environ['DART_API_KEY']
service_account_str = os.environ['GOOGLE_CREDENTIALS_JSON']
sheet_id = os.environ['GOOGLE_SHEET_ID']

# 2. êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦
creds = json.loads(service_account_str)
gc = gspread.service_account_from_dict(creds)
sh = gc.open_by_key(sheet_id)

# --- [JSON íŒŒì‹±] ---
def fetch_dart_json(url, params):
    try:
        res = requests.get(url, params=params)
        if res.status_code == 200:
            data = res.json()
            if data.get('status') == '000' and 'list' in data:
                return pd.DataFrame(data['list'])
    except Exception as e:
        print(f"JSON API ì—ëŸ¬: {e}")
    return pd.DataFrame()

# --- [XML ì›ë¬¸ ì¡±ì§‘ê²Œ íŒŒì‹± (ì •ê·œì‹ ì´ˆì •ë°€ ì—…ê·¸ë ˆì´ë“œ)] ---
def extract_xml_details(api_key, rcept_no):
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {'crtfc_key': api_key, 'rcept_no': rcept_no}
    
    extracted = {
        'board_date': '-', 'issue_price': '-', 'base_price': '-', 'discount': '-',
        'pay_date': '-', 'div_date': '-', 'list_date': '-', 'investor': 'ì›ë¬¸ì°¸ì¡°'
    }
    
    try:
        res = requests.get(url, params=params, stream=True)
        if res.status_code == 200:
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_filename = [name for name in z.namelist() if name.endswith('.xml')][0]
                with z.open(xml_filename) as f:
                    xml_content = f.read().decode('utf-8')
                    soup = BeautifulSoup(xml_content, 'html.parser')
                    raw_text = soup.get_text(separator=' ', strip=True)
                    
                    # ğŸ’¡ [ì¶”ê°€] ë‚ ì§œë¥¼ YYYYë…„ MMì›” DDì¼ ë¡œ ê¹”ë”í•˜ê²Œ ê°•ì œ í¬ë§·íŒ…í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
                    def fix_date(raw_date_str):
                        if not raw_date_str: return '-'
                        # ìˆ«ìë§Œ 3ê°œ(ì—°, ì›”, ì¼) ë½‘ì•„ëƒ„
                        nums = re.findall(r'\d+', raw_date_str)
                        if len(nums) >= 3:
                            return f"{nums[0]}ë…„ {nums[1].zfill(2)}ì›” {nums[2].zfill(2)}ì¼"
                        return raw_date_str + "ì¼" # ìˆ«ìê°€ ë¶€ì¡±í•˜ë©´ ì„ì‹œë°©í¸ìœ¼ë¡œ 'ì¼'ë§Œ ë¶™ì„
                    
                    # 1. í™•ì •ë°œí–‰ê°€ ì¶”ì¶œ (ê¸€ì ì‚¬ì´ ì¡ë¬¸ì ë¬´ì‹œí•˜ê³  ì²« ìˆ«ì ë§¤ì¹­)
                    issue = re.search(r'ë°œí–‰ê°€ì•¡[^\d]*([0-9]{1,3}(?:,[0-9]{3})*)', raw_text)
                    if issue: extracted['issue_price'] = issue.group(1).strip()
                    
                    # 2. ê¸°ì¤€ì£¼ê°€ ì¶”ì¶œ
                    base = re.search(r'ê¸°ì¤€ì£¼ê°€[^\d]*([0-9]{1,3}(?:,[0-9]{3})*)', raw_text)
                    if base: extracted['base_price'] = base.group(1).strip()
                    
                    # 3. í• ì¸/í• ì¦ë¥  ì¶”ì¶œ (ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ê°€ ì‚´ë„ë¡ ì •ê·œì‹ í•€ì…‹ ìˆ˜ì • ì™„ë£Œ!)
                    disc = re.search(r'í• \s*[ì¸ì¦]\s*ìœ¨[^\d\+\-]*([\-\+]?[0-9\.]+)', raw_text)
                    if disc: extracted['discount'] = disc.group(1).strip() + "%"
                    
                    # 4. ë‚ ì§œ ì¶”ì¶œ (ì´ì‚¬íšŒ, ë‚©ì…ì¼, ë°°ë‹¹ê¸°ì‚°ì¼, ìƒì¥ì˜ˆì •ì¼) + ğŸ’¡ fix_date ì ìš©!
                    board = re.search(r'ì´ì‚¬íšŒê²°ì˜ì¼[^\d]*(\d{4}[\-\.ë…„\s]+\d{1,2}[\-\.ì›”\s]+\d{1,2})', raw_text)
                    if board: extracted['board_date'] = fix_date(board.group(1).strip())
                    
                    pay = re.search(r'ë‚©\s*ì…\s*ì¼[^\d]*(\d{4}[\-\.ë…„\s]+\d{1,2}[\-\.ì›”\s]+\d{1,2})', raw_text)
                    if pay: extracted['pay_date'] = fix_date(pay.group(1).strip())
                    
                    div = re.search(r'ë°°ë‹¹ê¸°ì‚°ì¼[^\d]*(\d{4}[\-\.ë…„\s]+\d{1,2}[\-\.ì›”\s]+\d{1,2})', raw_text)
                    if div: extracted['div_date'] = fix_date(div.group(1).strip())
                    
                    list_d = re.search(r'ìƒì¥\s*ì˜ˆì •ì¼[^\d]*(\d{4}[\-\.ë…„\s]+\d{1,2}[\-\.ì›”\s]+\d{1,2})', raw_text)
                    if list_d: extracted['list_date'] = fix_date(list_d.group(1).strip())
                    
                    # 5. íˆ¬ìì
                    if "ì œ3ìë°°ì •" in raw_text: extracted['investor'] = "ì œ3ìë°°ì • (ì›ë¬¸ì°¸ì¡°)"

    except Exception as e:
        print(f"ë¬¸ì„œ XML ì—ëŸ¬ ({rcept_no}): {e}")
        
    return extracted

# ì•ˆì „í•œ ìˆ«ì ë³€í™˜ í•¨ìˆ˜
def to_int(val):
    try:
        if pd.isna(val) or str(val).strip() == '': return 0
        return int(float(str(val).replace(',', '').strip()))
    except:
        return 0

def get_and_update_yusang():
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=7)).strftime('%Y%m%d')

    print("ìµœê·¼ 7ì¼ ìœ ìƒì¦ì ê³µì‹œ íƒìƒ‰ ì¤‘ (ë°ì´í„° ìµœì‹ í™” ê²€ì¦ ë¡œì§ í¬í•¨)...")
    
    list_url = "https://opendart.fss.or.kr/api/list.json"
    list_params = {
        'crtfc_key': dart_key, 'bgn_de': start_date, 'end_de': end_date, 
        'pblntf_ty': 'B', 'pblntf_detail_ty': 'B001', 'page_count': '100'
    }
    all_filings = fetch_dart_json(list_url, list_params)

    if all_filings.empty:
        print("ìµœê·¼ 7ì¼ê°„ ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_filtered = all_filings[all_filings['report_nm'].str.contains('ìœ ìƒì¦ìê²°ì •', na=False)]
    if df_filtered.empty:
        print("â„¹ï¸ ìœ ìƒì¦ì ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    corp_codes = df_filtered['corp_code'].unique()
    detail_dfs = []
    
    for code in corp_codes:
        detail_params = {'crtfc_key': dart_key, 'corp_code': code, 'bgn_de': start_date, 'end_de': end_date}
        df_detail = fetch_dart_json('https://opendart.fss.or.kr/api/piicDecsn.json', detail_params)
        if not df_detail.empty:
            detail_dfs.append(df_detail)
            
    if not detail_dfs:
        print("â„¹ï¸ ìƒì„¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df_combined = pd.concat(detail_dfs, ignore_index=True)
    
    # ìƒì¥ì‹œì¥(corp_cls) ì´ë¦„ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ ëª©ë¡ì—ì„œëŠ” rcept_noë§Œ ê°€ì ¸ì™€ ë³‘í•©
    df_merged = pd.merge(df_combined, df_filtered[['rcept_no']], on='rcept_no', how='inner')
    
    worksheet = sh.worksheet('ìœ ìƒì¦ì')
    
    # ğŸ’¡ [ì¶”ê°€] Recheck + Diff + Update ë¡œì§ì„ ìœ„í•œ ê¸°ì¡´ ì‹œíŠ¸ ë°ì´í„° ì „ì²´ ë¶ˆëŸ¬ì˜¤ê¸°
    all_sheet_data = worksheet.get_all_values()
    existing_data_dict = {}
    
    # êµ¬ê¸€ ì‹œíŠ¸ì— ìˆëŠ” ë°ì´í„°ë¥¼ { 'ì ‘ìˆ˜ë²ˆí˜¸': { 'í–‰ë²ˆí˜¸': 2, 'ë°ì´í„°': ['ê°’1', 'ê°’2'...] } } í˜•íƒœë¡œ ë©”ëª¨ë¦¬ì— ì €ì¥
    for idx, row_data in enumerate(all_sheet_data):
        if len(row_data) >= 20: # 20ë²ˆì§¸ ì¹¸(Tì—´)ì´ ì ‘ìˆ˜ë²ˆí˜¸
            rcept_val = str(row_data[19]).strip()
            existing_data_dict[rcept_val] = {
                'row_idx': idx + 1, # êµ¬ê¸€ ì‹œíŠ¸ëŠ” 1í–‰ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1
                'data': [str(x).strip() for x in row_data] # ê³µë°± ì œê±° í›„ ë¬¸ìì—´ë¡œ ì €ì¥
            }
            
    data_to_add = []
    cls_map = {'Y': 'ìœ ê°€', 'K': 'ì½”ìŠ¤ë‹¥', 'N': 'ì½”ë„¥ìŠ¤', 'E': 'ê¸°íƒ€'}
    
    # ğŸ’¡ [ìˆ˜ì •] í•„í„°ë§ ì—†ì´ ì¼ë‹¨ ìµœê·¼ 7ì¼ì¹˜ ê³µì‹œ ì „ì²´ë¥¼ í›‘ìœ¼ë©° ë³€ê²½ì‚¬í•­(Diff)ì´ ìˆëŠ”ì§€ ê²€ì‚¬í•©ë‹ˆë‹¤.
    for _, row in df_merged.iterrows():
        rcept_no = str(row.get('rcept_no', ''))
        corp_name = row.get('corp_name', '')
        
        xml_data = extract_xml_details(dart_key, rcept_no)
        
        # 1. ìƒì¥ì‹œì¥ (ì—ëŸ¬ í•´ê²°)
        market = cls_map.get(row.get('corp_cls', ''), 'ê¸°íƒ€')
        method = row.get('ic_mthn', '')
        
        # 2. ì£¼ì‹ìˆ˜ & ì²œ ë‹¨ìœ„ ì½¤ë§ˆ
        ostk = to_int(row.get('nstk_ostk_cnt'))
        estk = to_int(row.get('nstk_estk_cnt'))
        new_shares = ostk + estk
        product = "ë³´í†µì£¼" if ostk > 0 else "ê¸°íƒ€ì£¼"
        
        old_ostk = to_int(row.get('bfic_tisstk_ostk'))
        old_estk = to_int(row.get('bfic_tisstk_estk'))
        old_shares = old_ostk + old_estk
        
        new_shares_str = f"{new_shares:,}"  # ì‰¼í‘œ ì¶”ê°€
        old_shares_str = f"{old_shares:,}"  # ì‰¼í‘œ ì¶”ê°€
        
        # 3. ì¦ìë¹„ìœ¨ (%)
        ratio = f"{(new_shares / old_shares * 100):.2f}%" if old_shares > 0 else "-"
        
        # 4. í™•ì •ë°œí–‰ê¸ˆì•¡ (ì–µì› ë‹¨ìœ„, ì†Œìˆ˜ì  2ìë¦¬ ì„¸ë°€í•˜ê²Œ)
        fclt = to_int(row.get('fdpp_fclt'))
        bsninh = to_int(row.get('fdpp_bsninh'))
        op = to_int(row.get('fdpp_op'))
        dtrp = to_int(row.get('fdpp_dtrp'))
        ocsa = to_int(row.get('fdpp_ocsa'))
        etc = to_int(row.get('fdpp_etc'))
        
        total_amt = fclt + bsninh + op + dtrp + ocsa + etc
        total_amt_uk = f"{(total_amt / 100000000):,.2f}" if total_amt > 0 else "0.00"
        
        # ìê¸ˆìš©ë„ ì¶”ì¶œ
        purposes = []
        if fclt > 0: purposes.append("ì‹œì„¤")
        if bsninh > 0: purposes.append("ì˜ì—…ì–‘ìˆ˜")
        if op > 0: purposes.append("ìš´ì˜")
        if dtrp > 0: purposes.append("ì±„ë¬´ìƒí™˜")
        if ocsa > 0: purposes.append("íƒ€ë²•ì¸ì¦ê¶Œ")
        if etc > 0: purposes.append("ê¸°íƒ€")
        purpose_str = ", ".join(purposes)
        
        link = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
        
        # ìƒˆë¡­ê²Œ ë§Œë“¤ì–´ë‚¸ ìµœì‹  íŒ©íŠ¸ ë°ì´í„° í•œ ì¤„
        new_row = [
            corp_name,                  # 1
            market,                     # 2 (ë³µêµ¬ë¨)
            xml_data['board_date'],     # 3
            method,                     # 4
            product,                    # 5
            new_shares_str,             # 6 (ì‰¼í‘œ ì¶”ê°€)
            xml_data['issue_price'],    # 7 (ì—…ê·¸ë ˆì´ë“œ)
            xml_data['base_price'],     # 8 (ì—…ê·¸ë ˆì´ë“œ)
            total_amt_uk,               # 9 (ì†Œìˆ˜ì  ì¶”ê°€)
            xml_data['discount'],       # 10 (ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ì¶”ê°€ë¨!)
            old_shares_str,             # 11 (ì‰¼í‘œ ì¶”ê°€)
            ratio,                      # 12 (ë¹„ìœ¨ ë³µêµ¬)
            xml_data['pay_date'],       # 13
            xml_data['div_date'],       # 14
            xml_data['list_date'],      # 15
            xml_data['board_date'],     # 16
            purpose_str,                # 17
            xml_data['investor'],       # 18
            link,                       # 19
            rcept_no                    # 20
        ]
        
        # ë¹„êµë¥¼ ìœ„í•´ ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´(String)ë¡œ ë³€í™˜
        new_row_str = [str(x).strip() for x in new_row]
        
        # ğŸ’¡ [í•µì‹¬ ë¡œì§] ê¸°ì¡´ ì‹œíŠ¸ì— ìˆëŠ” ë°ì´í„°ì¸ì§€ ê²€ì¦ ë° ì—…ë°ì´íŠ¸
        if rcept_no in existing_data_dict:
            existing_row_str = existing_data_dict[rcept_no]['data']
            
            # ê¸¸ì´ë¥¼ ë§ì¶°ì„œ 1:1 ë¹„êµë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ì—ëŸ¬ ë°©ì§€ìš© íŒ¨ë”©)
            existing_row_str += [''] * (len(new_row_str) - len(existing_row_str))
            existing_row_str = existing_row_str[:len(new_row_str)]
            
            # Diff ê²€ì‚¬: í•˜ë‚˜ë¼ë„ ê°’ì´ ë‹¤ë¥´ë‹¤ë©´ ì—…ë°ì´íŠ¸ ì‹¤í–‰!
            if new_row_str != existing_row_str:
                row_idx = existing_data_dict[rcept_no]['row_idx']
                try:
                    worksheet.update(range_name=f'A{row_idx}:T{row_idx}', values=[new_row])
                except TypeError:
                    worksheet.update(f'A{row_idx}:T{row_idx}', [new_row])
                print(f" ğŸ”„ {corp_name}: ë°ì´í„° ë³€ê²½ ê°ì§€! ìµœì‹  ë‚´ìš©ìœ¼ë¡œ ìë™ ë®ì–´ì“°ê¸° ì™„ë£Œ (í–‰: {row_idx})")
            else:
                print(f" â© {corp_name}: ë³€ê²½ì‚¬í•­ ì—†ìŒ (íŒ¨ìŠ¤)")
                
        else:
            # ì‹œíŠ¸ì— ì•„ì˜ˆ ì—†ëŠ” ì ‘ìˆ˜ë²ˆí˜¸ë¼ë©´ ì‹ ê·œ ë°ì´í„° ë°”êµ¬ë‹ˆì— ë‹´ê¸°
            print(f" ğŸ†• {corp_name}: ì‹ ê·œ ê³µì‹œ ë°œê²¬! ì¶”ê°€ ëŒ€ê¸° ì¤‘...")
            data_to_add.append(new_row)
        
    # ì‹ ê·œ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë§¨ ë°‘ì— ì¼ê´„ ì¶”ê°€
    if data_to_add:
        worksheet.append_rows(data_to_add)
        print(f"âœ… ìœ ìƒì¦ì: ì‹ ê·œ ë°ì´í„° {len(data_to_add)}ê±´ ì¼ê´„ ì¶”ê°€ ì™„ë£Œ!")
    else:
        print("âœ… ìœ ìƒì¦ì: ìƒˆë¡œ ì¶”ê°€í•  ê³µì‹œëŠ” ì—†ìœ¼ë©° ë°ì´í„° ìµœì‹ í™” ì ê²€ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    get_and_update_yusang()
