import os
import json
import gspread
import pandas as pd
import requests
import zipfile
import io
import re
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

# ==========================================
# 1. ì´ˆê¸° ì…‹íŒ…: API í‚¤ì™€ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²°
# ==========================================
dart_key = os.environ['DART_API_KEY']
service_account_str = os.environ['GOOGLE_CREDENTIALS_JSON']
sheet_id = os.environ['GOOGLE_SHEET_ID']

creds = json.loads(service_account_str)
gc = gspread.service_account_from_dict(creds)
sh = gc.open_by_key(sheet_id)

# ==========================================
# 2. DART API ê¸°ë³¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (JSON)
# ==========================================
def fetch_dart_json(url, params):
    try:
        res = requests.get(url, params=params)
        if res.status_code == 200:
            data = res.json()
            if data.get('status') == '000' and 'list' in data:
                return pd.DataFrame(data['list'])
    except Exception as e:
        print(f"JSON API ì—ëŸ¬: {e}")
    return pd.DataFrame()

# ==========================================
# 3. ğŸ’¡ ì™„ë²½ ìŠ¤ìºë„ˆ: í‘œ(Table) êµ¬ì¡° ë¶„ì„ ì—”ì§„
# ==========================================
def extract_xml_details(api_key, rcept_no):
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {'crtfc_key': api_key, 'rcept_no': rcept_no}
    
    # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ (ë¹ˆì¹¸)
    extracted = {
        'board_date': '-', 'issue_price': '-', 'base_price': '-', 'discount': '-',
        'pay_date': '-', 'div_date': '-', 'list_date': '-', 'investor': 'ì›ë¬¸ì°¸ì¡°'
    }
    
    try:
        res = requests.get(url, params=params, stream=True)
        if res.status_code == 200:
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_filename = [name for name in z.namelist() if name.endswith('.xml')][0]
                with z.open(xml_filename) as f:
                    xml_content = f.read().decode('utf-8')
                    soup = BeautifulSoup(xml_content, 'html.parser')
                    
                    raw_data = {}
                    
                    # ğŸ’¡ í‘œì˜ 'í–‰(tr)' ë‹¨ìœ„ë¡œë§Œ ìª¼ê°œì„œ ì½ìŒ -> ë‹¤ë¥¸ ì¤„ì˜ ë°ì´í„°ë¥¼ í›”ì³ì˜¤ëŠ” ì˜¤ë¥˜ ì›ì²œ ì°¨ë‹¨
                    for tr in soup.find_all('tr'):
                        cells = tr.find_all(['th', 'td'])
                        
                        for i in range(len(cells)):
                            header_raw = cells[i].get_text(strip=True)
                            header_clean = re.sub(r'\s+', '', header_raw.replace('\xa0', ''))
                            
                            # í˜„ì¬ ì¹¸ì´ ì œëª©ì´ë©´, ë¬´ì¡°ê±´ 'ê°™ì€ ì¤„ ì˜¤ë¥¸ìª½ ì¹¸'ì˜ ë°ì´í„°ë§Œ ê¸ì–´ì˜´
                            if i + 1 < len(cells):
                                val_raw = " ".join([c.get_text(separator=' ', strip=True) for c in cells[i+1:]])
                                
                                if 'issue_price' not in raw_data and re.search(r'(1ì£¼ë‹¹|í™•ì •|ì˜ˆì •|ëª¨ì§‘|ë°œí–‰|ì‹ ì£¼).*ë°œí–‰ê°€ì•¡', header_clean):
                                    raw_data['issue_price'] = val_raw
                                elif 'base_price' not in raw_data and re.search(r'^ê¸°ì¤€(ì£¼ê°€|ë°œí–‰ê°€ì•¡|ê°€ì•¡|ë‹¨ê°€|ì£¼ë‹¹ê°€ì•¡)', header_clean):
                                    raw_data['base_price'] = val_raw
                                elif 'discount' not in raw_data and re.search(r'(í• ì¸|í• ì¦)[ìœ¨ë¥ ]', header_clean):
                                    raw_data['discount'] = val_raw
                                    raw_data['discount_header'] = header_clean
                                elif 'board_date' not in raw_data and re.search(r'(ìµœì´ˆ)?ì´ì‚¬íšŒê²°ì˜ì¼', header_clean):
                                    raw_data['board_date'] = val_raw
                                elif 'pay_date' not in raw_data and re.search(r'(ë‚©ì…ì¼|ì£¼ê¸ˆë‚©ì…ê¸°ì¼)', header_clean):
                                    raw_data['pay_date'] = val_raw
                                elif 'div_date' not in raw_data and re.search(r'(ì‹ ì£¼ì˜)?ë°°ë‹¹ê¸°ì‚°ì¼', header_clean):
                                    raw_data['div_date'] = val_raw
                                elif 'list_date' not in raw_data and re.search(r'(ì‹ ì£¼ê¶Œêµë¶€ì˜ˆì •ì¼|ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼|ìƒì¥ì˜ˆì •ì¼|ì‹ ì£¼ìƒì¥ì˜ˆì •ì¼)', header_clean):
                                    raw_data['list_date'] = val_raw

                    # --- [í´ë¦¬ë‹ 1] ê°€ê²© íŒ©íŠ¸ ì²´í¬ ---
                    def clean_price(text):
                        if not text: return '-'
                        t_clean = re.sub(r'[\s,ì›]', '', text)
                        if re.search(r'^(ë¯¸ì •|í•´ë‹¹ì—†ìŒ|ê¸°ì¬ìƒëµ|-)', t_clean): return '-'
                        
                        nums = re.findall(r'(?<!\d)([1-9]\d{2,})(?!\d)', t_clean)
                        for val_str in nums:
                            val = int(val_str)
                            if val not in [2023, 2024, 2025, 2026, 2027]:
                                return f"{val:,}"
                        return '-'
                        
                    # --- [í´ë¦¬ë‹ 2] ë‚ ì§œ íŒ©íŠ¸ ì²´í¬ ---
                    def clean_date(text):
                        if not text: return '-'
                        t_clean = re.sub(r'\s+', '', text)
                        if re.search(r'^(ë¯¸ì •|í•´ë‹¹ì—†ìŒ|ê¸°ì¬ìƒëµ|-)', t_clean): return '-'
                        
                        m = re.search(r'(20[2-3]\d)[\-\.ë…„/]([0-1]?\d)[\-\.ì›”/]([0-3]?\d)', t_clean)
                        if m:
                            y, m_num, d_num = m.groups()
                            return f"{y}ë…„ {m_num.zfill(2)}ì›” {d_num.zfill(2)}ì¼"
                        return '-'
                        
                    # --- [í´ë¦¬ë‹ 3] í• ì¸ìœ¨/í• ì¦ë¥  ì™„ë²½ ê²€ì¦ ---
                    def clean_discount(text, issue_p, base_p, header_text):
                        if not text: return '-'
                        t_clean = re.sub(r'\s+', '', text)
                        if re.search(r'^(ë¯¸ì •|í•´ë‹¹ì‚¬í•­ì—†ìŒ|í•´ë‹¹ì—†ìŒ|ê¸°ì¬ìƒëµ|-)', t_clean): return "0.00%"
                        
                        # ìˆ˜í•™ì  ë¶€í˜¸ íŒë³„
                        math_sign = 0
                        if issue_p != '-' and base_p != '-':
                            try:
                                i_v = float(issue_p.replace(',', ''))
                                b_v = float(base_p.replace(',', ''))
                                if b_v > 0:
                                    if i_v > b_v: math_sign = 1    # í• ì¦(+)
                                    elif i_v < b_v: math_sign = -1 # í• ì¸(-)
                            except: pass
                            
                        # ìˆ«ì ì¶”ì¶œ
                        m = re.search(r'([+\-]?\d+(?:\.\d+)?)', t_clean)
                        if m:
                            val_str = m.group(1)
                            try: val = float(val_str)
                            except: return '-'
                            
                            if val == 0: return "0.00%"
                            if abs(val) > 100: return '-' # í˜ì´ì§€ ë²ˆí˜¸ ì“°ë ˆê¸°ê°’ ë°©ì–´
                            
                            val_abs = abs(val)
                            
                            # 1. ìˆ˜í•™ì  íŒ©íŠ¸ê°€ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ìš°ì„ 
                            if math_sign != 0:
                                return f"{val_abs * math_sign:+.2f}%"
                            # 2. ê³„ì‚° ë¶ˆê°€ ì‹œ í…ìŠ¤íŠ¸ ê¸°í˜¸ ë° ë¬¸ë§¥ íŒŒì•…
                            else:
                                if '-' in val_str: return f"{-val_abs:+.2f}%"
                                elif '+' in val_str: return f"{val_abs:+.2f}%"
                                else:
                                    if 'í• ì¦' in header_text and 'í• ì¸' not in header_text: return f"+{val_abs:.2f}%"
                                    else: return f"{-val_abs:+.2f}%"
                        return '-'

                    # í´ë¦¬ë‹ ê¸°ê³„ ê°€ë™ ë° ê²°ê³¼ ì €ì¥
                    extracted['issue_price'] = clean_price(raw_data.get('issue_price'))
                    extracted['base_price'] = clean_price(raw_data.get('base_price'))
                    extracted['discount'] = clean_discount(raw_data.get('discount'), extracted['issue_price'], extracted['base_price'], raw_data.get('discount_header', ''))
                    extracted['board_date'] = clean_date(raw_data.get('board_date'))
                    extracted['pay_date'] = clean_date(raw_data.get('pay_date'))
                    extracted['div_date'] = clean_date(raw_data.get('div_date'))
                    extracted['list_date'] = clean_date(raw_data.get('list_date'))
                    
                    full_text = soup.get_text(separator=' ', strip=True).replace(' ', '')
                    if "ì œ3ìë°°ì •" in full_text: extracted['investor'] = "ì œ3ìë°°ì • (ì›ë¬¸ì°¸ì¡°)"

    except Exception as e:
        print(f"ë¬¸ì„œ XML ì—ëŸ¬ ({rcept_no}): {e}")
        
    return extracted

def to_int(val):
    try:
        if pd.isna(val) or str(val).strip() == '': return 0
        return int(float(str(val).replace(',', '').strip()))
    except:
        return 0

# ==========================================
# 4. ë©”ì¸ ì‹¤í–‰ ë° ë®ì–´ì“°ê¸° ë¡œì§
# ==========================================
def get_and_update_yusang():
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=12)).strftime('%Y%m%d')

    print("ğŸš€ 100% ì™„ë²½ ìŠ¤ìºë„ˆ ê°€ë™! ë°ì´í„° ê²€ì¦ ë° ë®ì–´ì“°ê¸° ì§„í–‰ ì¤‘...")
    
    list_url = "https://opendart.fss.or.kr/api/list.json"
    list_params = {
        'crtfc_key': dart_key, 'bgn_de': start_date, 'end_de': end_date, 
        'pblntf_ty': 'B', 'pblntf_detail_ty': 'B001', 'page_count': '100',
        'last_reprt_at': 'Y'
    }
    all_filings = fetch_dart_json(list_url, list_params)

    if all_filings.empty:
        print("ìµœê·¼ ì§€ì • ê¸°ê°„ ë‚´ ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_filtered = all_filings[all_filings['report_nm'].str.contains('ìœ ìƒì¦ìê²°ì •', na=False)].copy()
    if df_filtered.empty:
        print("â„¹ï¸ ìœ ìƒì¦ì ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df_filtered['corp_cls'] = df_filtered['corp_cls'].fillna('')
        
    corp_codes = df_filtered['corp_code'].unique()
    detail_dfs = []
    
    for code in corp_codes:
        detail_params = {'crtfc_key': dart_key, 'corp_code': code, 'bgn_de': start_date, 'end_de': end_date}
        df_detail = fetch_dart_json('https://opendart.fss.or.kr/api/piicDecsn.json', detail_params)
        if not df_detail.empty:
            detail_dfs.append(df_detail)
            
    if not detail_dfs:
        print("â„¹ï¸ ìƒì„¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df_combined = pd.concat(detail_dfs, ignore_index=True)
    df_combined = df_combined.drop(columns=['corp_cls'], errors='ignore')
    
    df_merged = pd.merge(df_combined, df_filtered[['rcept_no', 'corp_cls', 'report_nm']], on='rcept_no', how='left')
    
    worksheet = sh.worksheet('ìœ ìƒì¦ì')
    existing_rcept_nos = worksheet.col_values(21) 
    
    data_to_add = []
    cls_map = {'Y': 'ìœ ê°€', 'K': 'ì½”ìŠ¤ë‹¥', 'N': 'ì½”ë„¥ìŠ¤', 'E': 'ê¸°íƒ€'}
    
    for _, row in df_merged.iterrows():
        rcept_no = str(row.get('rcept_no', ''))
        corp_name = row.get('corp_name', '')
        report_nm = row.get('report_nm', '') 
        
        xml_data = extract_xml_details(dart_key, rcept_no)
        
        market = cls_map.get(row.get('corp_cls', ''), 'ê¸°íƒ€')
        method = row.get('ic_mthn', '')
        
        ostk = to_int(row.get('nstk_ostk_cnt'))
        estk = to_int(row.get('nstk_estk_cnt'))
        new_shares = ostk + estk
        product = "ë³´í†µì£¼" if ostk > 0 else "ê¸°íƒ€ì£¼"
        
        old_ostk = to_int(row.get('bfic_tisstk_ostk'))
        old_estk = to_int(row.get('bfic_tisstk_estk'))
        old_shares = old_ostk + old_estk
        
        new_shares_str = f"{new_shares:,}"
        old_shares_str = f"{old_shares:,}"
        
        ratio = f"{(new_shares / old_shares * 100):.2f}%" if old_shares > 0 else "-"
        
        fclt = to_int(row.get('fdpp_fclt'))
        bsninh = to_int(row.get('fdpp_bsninh'))
        op = to_int(row.get('fdpp_op'))
        dtrp = to_int(row.get('fdpp_dtrp'))
        ocsa = to_int(row.get('fdpp_ocsa'))
        etc = to_int(row.get('fdpp_etc'))
        
        total_amt = fclt + bsninh + op + dtrp + ocsa + etc
        total_amt_uk = f"{(total_amt / 100000000):,.2f}" if total_amt > 0 else "0.00"
        
        purposes = []
        if fclt > 0: purposes.append("ì‹œì„¤")
        if bsninh > 0: purposes.append("ì˜ì—…ì–‘ìˆ˜")
        if op > 0: purposes.append("ìš´ì˜")
        if dtrp > 0: purposes.append("ì±„ë¬´ìƒí™˜")
        if ocsa > 0: purposes.append("íƒ€ë²•ì¸ì¦ê¶Œ")
        if etc > 0: purposes.append("ê¸°íƒ€")
        purpose_str = ", ".join(purposes)
        
        link = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
        
        new_row = [
            corp_name,                           
            report_nm,                           
            market,                              
            xml_data['board_date'],              
            method,                              
            product,                             
            new_shares_str,                      
            xml_data.get('issue_price', '-'),    
            xml_data.get('base_price', '-'),     
            total_amt_uk,                        
            xml_data.get('discount', '-'),       
            old_shares_str,                      
            ratio,                               
            xml_data['pay_date'],                
            xml_data['div_date'],                
            xml_data['list_date'],               
            xml_data['board_date'],              
            purpose_str,                         
            xml_data['investor'],                
            link,                                
            rcept_no                             
        ]
        
        # ğŸ’¡ ì—ëŸ¬ ë°ì´í„° ì™„ë²½ ë®ì–´ì“°ê¸° ë¡œì§
        if rcept_no in existing_rcept_nos:
            row_idx = existing_rcept_nos.index(rcept_no) + 1 
            try:
                worksheet.update(range_name=f'A{row_idx}:U{row_idx}', values=[new_row])
            except TypeError:
                worksheet.update(f'A{row_idx}:U{row_idx}', [new_row])
            print(f" ğŸ”„ {corp_name}: ì™„ë²½ ìŠ¤ìº” ì™„ë£Œ! ê¸°ì¡´ ë°ì´í„° ë¹ˆí‹ˆì—†ì´ ë®ì–´ì¼ìŠµë‹ˆë‹¤! (í–‰: {row_idx})")
            
        else:
            print(f" ğŸ†• {corp_name}: ì‹ ê·œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
            data_to_add.append(new_row)
        
    if data_to_add:
        worksheet.append_rows(data_to_add)
        print(f"âœ… ë! ì‹ ê·œ ê³µì‹œ {len(data_to_add)}ê±´ ì™„ë²½í•˜ê²Œ ì¶”ê°€ ì™„ë£Œ!")
    else:
        print("âœ… ë! ì˜¤ë¥˜ ë‚¬ë˜ ê¸°ì¡´ ë°ì´í„°ë“¤ 100% ê¹”ë”í•˜ê²Œ ë³µêµ¬ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    get_and_update_yusang()
