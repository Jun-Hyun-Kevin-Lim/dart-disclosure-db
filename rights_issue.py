import os
import json
import gspread
import pandas as pd
import requests
import zipfile
import io
import re
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

# 1. GitHub Secrets ì„¤ì •ê°’
dart_key = os.environ['DART_API_KEY']
service_account_str = os.environ['GOOGLE_CREDENTIALS_JSON']
sheet_id = os.environ['GOOGLE_SHEET_ID']

# 2. êµ¬ê¸€ ì‹œíŠ¸ ì¸ì¦
creds = json.loads(service_account_str)
gc = gspread.service_account_from_dict(creds)
sh = gc.open_by_key(sheet_id)

# --- [JSON íŒŒì‹±] ---
def fetch_dart_json(url, params):
    try:
        res = requests.get(url, params=params)
        if res.status_code == 200:
            data = res.json()
            if data.get('status') == '000' and 'list' in data:
                return pd.DataFrame(data['list'])
    except Exception as e:
        print(f"JSON API ì—ëŸ¬: {e}")
    return pd.DataFrame()

# --- [XML ì›ë¬¸ ì¡±ì§‘ê²Œ íŒŒì‹± (í• ì¸ìœ¨ ì§‘ì¤‘ ê³µëµ)] ---
def extract_xml_details(api_key, rcept_no):
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {'crtfc_key': api_key, 'rcept_no': rcept_no}
    
    extracted = {
        'board_date': '-', 'issue_price': '-', 'base_price': '-', 'discount': '-',
        'pay_date': '-', 'div_date': '-', 'list_date': '-', 'investor': 'ì›ë¬¸ì°¸ì¡°'
    }
    
    try:
        res = requests.get(url, params=params, stream=True)
        if res.status_code == 200:
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_filename = [name for name in z.namelist() if name.endswith('.xml')][0]
                with z.open(xml_filename) as f:
                    xml_content = f.read().decode('utf-8')
                    soup = BeautifulSoup(xml_content, 'html.parser')
                    
                    for tag in soup.find_all(['td', 'th', 'p', 'div']):
                        tag.append(' ')
                        
                    raw_text = soup.get_text(separator=' ', strip=True)
                    # ì—¬ë°±ì„ 1ì¹¸ìœ¼ë¡œë§Œ ì••ì¶• (ë‹¤ë¥¸ ê°’ì´ ë§ê°€ì§€ì§€ ì•Šê²Œ ìœ ì§€)
                    clean_text = re.sub(r'\s+', ' ', raw_text)
                    
                    # 1. ê°€ê²© ì¶”ì¶œ (ì•ˆì •ì ì¸ ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
                    def get_price(keyword):
                        for match in re.finditer(keyword, clean_text):
                            window = clean_text[match.end():match.end()+150]
                            nums = re.findall(r'(?<![\d\.])(?:[1-9]\d{0,2}(?:,\d{3})+|[1-9]\d{2,})(?![\d\.])', window)
                            for n in nums:
                                val = int(n.replace(',', ''))
                                if val >= 100 and val not in [2023, 2024, 2025, 2026, 2027]:
                                    return f"{val:,}"
                        return '-'
                        
                    extracted['issue_price'] = get_price(r'(?:í™•\s*ì •|ì˜ˆ\s*ì •)?\s*ë°œ\s*í–‰\s*ê°€\s*(?:ì•¡)?')
                    extracted['base_price'] = get_price(r'ê¸°\s*ì¤€\s*(?:ì£¼\s*ê°€|ë°œ\s*í–‰\s*ê°€\s*(?:ì•¡)?|ê°€\s*ì•¡)')
                    
                    # 2. ğŸ’¡ í• ì¸/í• ì¦ë¥  ì¶”ì¶œ (í• ì¸ìœ¨ ì§‘ì¤‘ ê³ ë„í™” ì—”ì§„)
                    def get_discount(issue_p, base_p):
                        # ê¸´ ë¬¸êµ¬ê¹Œì§€ ì™„ë²½í•˜ê²Œ ì¡ì•„ë‚´ëŠ” íŒ¨í„´
                        pattern = r'(ê¸°\s*ì¤€\s*ì£¼\s*ê°€\s*ì—\s*ëŒ€\s*í•œ\s*)?(í• \s*ì¸\s*[ë¥ ìœ¨]\s*ë˜\s*ëŠ”\s*í• \s*ì¦\s*[ë¥ ìœ¨]|í• \s*ì¸\s*[\(\[\{]?\s*í• \s*ì¦\s*[\)\]\}]?\s*[ë¥ ìœ¨]|í• \s*ì¸\s*[ë¥ ìœ¨]|í• \s*ì¦\s*[ë¥ ìœ¨])'
                        
                        extracted_val = None
                        val_str = ""
                        keyword = ""
                        
                        for match in re.finditer(pattern, clean_text):
                            keyword = match.group(0).replace(' ', '')
                            # ìˆ«ì ì°¾ì„ ë•Œë§Œ í•´ë‹¹ êµ¬ê°„ì˜ ë„ì–´ì“°ê¸°ë¥¼ ì—†ì• ì„œ ì •í™•íˆ ìºì¹˜
                            window = clean_text[match.end():match.end()+150].replace(' ', '')
                            
                            # ì†Œìˆ˜ì ì´ ìˆëŠ” ìˆ«ì ìš°ì„  íƒìƒ‰ (-2.80)
                            m = re.search(r'([\-\+]?\d+\.\d+)', window)
                            if not m:
                                # ì—†ìœ¼ë©´ %ê°€ ë¶™ì–´ìˆëŠ” ì •ìˆ˜ íƒìƒ‰ (10%)
                                m = re.search(r'([\-\+]?\d+)%', window)
                                
                            if m:
                                val_str = m.group(1)
                                extracted_val = float(val_str)
                                break
                                
                            if re.search(r'(í•´ë‹¹\s*ì‚¬í•­\s*ì—†ìŒ|í•´ë‹¹\s*ì—†ìŒ|-)', window[:20]):
                                return "0.00%"

                        if extracted_val is None:
                            return '-'
                            
                        if extracted_val == 0:
                            return "0.00%"

                        # --- ë¶€í˜¸(+, -) ê²°ì • ë¡œì§ ---
                        val_abs = abs(extracted_val)
                        final_sign = 0 
                        
                        # 1ë‹¨ê³„: ë¬¸ìì—´ ìì²´ì— ê¸°í˜¸ê°€ ìˆìœ¼ë©´ ìš°ì„  ì ìš©
                        if '-' in val_str: final_sign = -1
                        elif '+' in val_str: final_sign = 1
                            
                        # 2ë‹¨ê³„: ğŸ’¡ ìˆ˜í•™ì  í¬ë¡œìŠ¤ì²´í¬ (ë°œí–‰ê°€ vs ê¸°ì¤€ì£¼ê°€ ë¹„êµë¡œ ëª…í™•í•œ ë¶€í˜¸ í™•ì •)
                        if issue_p != '-' and base_p != '-':
                            try:
                                i_v = float(issue_p.replace(',', ''))
                                b_v = float(base_p.replace(',', ''))
                                if b_v > 0:
                                    if i_v > b_v: final_sign = 1    # ë¹„ì‹¸ê²Œ íŒ”ë©´ ë¬´ì¡°ê±´ í• ì¦(+)
                                    elif i_v < b_v: final_sign = -1 # ì‹¸ê²Œ íŒ”ë©´ ë¬´ì¡°ê±´ í• ì¸(-)
                            except:
                                pass
                                
                        # 3ë‹¨ê³„: ìˆ˜í•™ ì²´í¬ ë¶ˆê°€ & ë¶€í˜¸ ì—†ì„ ë•Œ ê¸€ìë¡œ ìœ ì¶”
                        if final_sign == 0:
                            if 'í• ì¦' in keyword and 'í• ì¸' not in keyword:
                                final_sign = 1
                            else:
                                final_sign = -1 # ê¸°ë³¸ê°’ì€ í• ì¸(-)
                                
                        return f"{val_abs * final_sign:+.2f}%"

                    extracted['discount'] = get_discount(extracted['issue_price'], extracted['base_price'])
                    
                    # 3. ë‚ ì§œ ì¶”ì¶œ (ì•ˆì •ì ì¸ ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
                    def get_date(keyword):
                        for match in re.finditer(keyword, clean_text):
                            window = clean_text[match.end():match.end()+150]
                            m = re.search(r'(20[2-3][0-9])\s*[\-\.ë…„]\s*([0-1]?[0-9])\s*[\-\.ì›”]\s*([0-3]?[0-9])', window)
                            if m:
                                y, m_num, d_num = m.groups()
                                return f"{y}ë…„ {m_num.zfill(2)}ì›” {d_num.zfill(2)}ì¼"
                        return '-'
                        
                    extracted['board_date'] = get_date(r'(?:ìµœ\s*ì´ˆ\s*)?ì´\s*ì‚¬\s*íšŒ\s*ê²°\s*ì˜\s*ì¼')
                    extracted['pay_date'] = get_date(r'(ë‚©\s*ì…\s*ì¼|ì£¼\s*ê¸ˆ\s*ë‚©\s*ì…\s*ê¸°\s*ì¼)')
                    extracted['div_date'] = get_date(r'(?:ì‹ \s*ì£¼\s*ì˜\s*)?ë°°\s*ë‹¹\s*ê¸°\s*ì‚°\s*ì¼')
                    extracted['list_date'] = get_date(r'(?:ì‹ \s*ì£¼\s*ê¶Œ\s*êµ\s*ë¶€\s*ì˜ˆ\s*ì •\s*ì¼|ìƒ\s*ì¥\s*ì˜ˆ\s*ì •\s*ì¼)')
                    
                    # 4. íˆ¬ìì
                    if "ì œ3ìë°°ì •" in clean_text: extracted['investor'] = "ì œ3ìë°°ì • (ì›ë¬¸ì°¸ì¡°)"

    except Exception as e:
        print(f"ë¬¸ì„œ XML ì—ëŸ¬ ({rcept_no}): {e}")
        
    return extracted

# ì•ˆì „í•œ ìˆ«ì ë³€í™˜ í•¨ìˆ˜
def to_int(val):
    try:
        if pd.isna(val) or str(val).strip() == '': return 0
        return int(float(str(val).replace(',', '').strip()))
    except:
        return 0

def get_and_update_yusang():
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=12)).strftime('%Y%m%d')

    print("ìµœê·¼ 12ì¼ ìœ ìƒì¦ì ê³µì‹œ íƒìƒ‰ ì¤‘ (í• ì¸ìœ¨ ì§‘ì¤‘ ì¹˜ë£Œ ë²„ì „)...")
    
    list_url = "https://opendart.fss.or.kr/api/list.json"
    list_params = {
        'crtfc_key': dart_key, 'bgn_de': start_date, 'end_de': end_date, 
        'pblntf_ty': 'B', 'pblntf_detail_ty': 'B001', 'page_count': '100',
        'last_reprt_at': 'Y'
    }
    all_filings = fetch_dart_json(list_url, list_params)

    if all_filings.empty:
        print("ìµœê·¼ ì§€ì • ê¸°ê°„ ë‚´ ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_filtered = all_filings[all_filings['report_nm'].str.contains('ìœ ìƒì¦ìê²°ì •', na=False)].copy()
    if df_filtered.empty:
        print("â„¹ï¸ ìœ ìƒì¦ì ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df_filtered['corp_cls'] = df_filtered['corp_cls'].fillna('')
        
    corp_codes = df_filtered['corp_code'].unique()
    detail_dfs = []
    
    for code in corp_codes:
        detail_params = {'crtfc_key': dart_key, 'corp_code': code, 'bgn_de': start_date, 'end_de': end_date}
        df_detail = fetch_dart_json('https://opendart.fss.or.kr/api/piicDecsn.json', detail_params)
        if not df_detail.empty:
            detail_dfs.append(df_detail)
            
    if not detail_dfs:
        print("â„¹ï¸ ìƒì„¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df_combined = pd.concat(detail_dfs, ignore_index=True)
    df_combined = df_combined.drop(columns=['corp_cls'], errors='ignore')
    
    df_merged = pd.merge(df_combined, df_filtered[['rcept_no', 'corp_cls', 'report_nm']], on='rcept_no', how='left')
    
    worksheet = sh.worksheet('ìœ ìƒì¦ì')
    existing_rcept_nos = worksheet.col_values(21) 
    
    new_data_df = df_merged[~df_merged['rcept_no'].astype(str).isin(existing_rcept_nos)]
    
    if new_data_df.empty:
        print("â„¹ï¸ ìƒˆë¡œ ì¶”ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    data_to_add = []
    cls_map = {'Y': 'ìœ ê°€', 'K': 'ì½”ìŠ¤ë‹¥', 'N': 'ì½”ë„¥ìŠ¤', 'E': 'ê¸°íƒ€'}
    
    for _, row in new_data_df.iterrows():
        rcept_no = str(row.get('rcept_no', ''))
        corp_name = row.get('corp_name', '')
        report_nm = row.get('report_nm', '') 
        
        print(f" -> {corp_name} ë°ì´í„° ì¶”ì¶œ ë° í¬ë§¤íŒ… ì ìš© ì¤‘...")
        
        xml_data = extract_xml_details(dart_key, rcept_no)
        
        market = cls_map.get(row.get('corp_cls', ''), 'ê¸°íƒ€')
        method = row.get('ic_mthn', '')
        
        ostk = to_int(row.get('nstk_ostk_cnt'))
        estk = to_int(row.get('nstk_estk_cnt'))
        new_shares = ostk + estk
        product = "ë³´í†µì£¼" if ostk > 0 else "ê¸°íƒ€ì£¼"
        
        old_ostk = to_int(row.get('bfic_tisstk_ostk'))
        old_estk = to_int(row.get('bfic_tisstk_estk'))
        old_shares = old_ostk + old_estk
        
        new_shares_str = f"{new_shares:,}"
        old_shares_str = f"{old_shares:,}"
        
        ratio = f"{(new_shares / old_shares * 100):.2f}%" if old_shares > 0 else "-"
        
        fclt = to_int(row.get('fdpp_fclt'))
        bsninh = to_int(row.get('fdpp_bsninh'))
        op = to_int(row.get('fdpp_op'))
        dtrp = to_int(row.get('fdpp_dtrp'))
        ocsa = to_int(row.get('fdpp_ocsa'))
        etc = to_int(row.get('fdpp_etc'))
        
        total_amt = fclt + bsninh + op + dtrp + ocsa + etc
        total_amt_uk = f"{(total_amt / 100000000):,.2f}" if total_amt > 0 else "0.00"
        
        purposes = []
        if fclt > 0: purposes.append("ì‹œì„¤")
        if bsninh > 0: purposes.append("ì˜ì—…ì–‘ìˆ˜")
        if op > 0: purposes.append("ìš´ì˜")
        if dtrp > 0: purposes.append("ì±„ë¬´ìƒí™˜")
        if ocsa > 0: purposes.append("íƒ€ë²•ì¸ì¦ê¶Œ")
        if etc > 0: purposes.append("ê¸°íƒ€")
        purpose_str = ", ".join(purposes)
        
        link = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
        
        new_row = [
            corp_name,                  
            report_nm,                  
            market,                     
            xml_data['board_date'],     
            method,                     
            product,                    
            new_shares_str,             
            xml_data.get('issue_price', '-'),    
            xml_data.get('base_price', '-'),     
            total_amt_uk,               
            xml_data.get('discount', '-'),       
            old_shares_str,             
            ratio,                      
            xml_data['pay_date'],       
            xml_data['div_date'],       
            xml_data['list_date'],      
            xml_data['board_date'],     
            purpose_str,                
            xml_data['investor'],       
            link,                       
            rcept_no                    
        ]
        
        data_to_add.append(new_row)
        
    worksheet.append_rows(data_to_add)
    print(f"âœ… ìœ ìƒì¦ì: ì•ˆì •í™” ë° í• ì¸ìœ¨ ì§‘ì¤‘ ê°œì„  ì™„ë£Œ! ì‹ ê·œ ë°ì´í„° {len(data_to_add)}ê±´ ì¶”ê°€ë¨!")

if __name__ == "__main__":
    get_and_update_yusang()
