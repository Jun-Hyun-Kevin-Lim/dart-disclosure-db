import os
import json
import gspread
import pandas as pd
import requests
import zipfile
import io
import re
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° API ì¸ì¦
# ==========================================
# GitHub Secrets ë“±ì— ì €ì¥ëœ í™˜ê²½ë³€ìˆ˜(API í‚¤, ì¸ì¦ì„œ ë“±)ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
dart_key = os.environ['DART_API_KEY']
service_account_str = os.environ['GOOGLE_CREDENTIALS_JSON']
sheet_id = os.environ['GOOGLE_SHEET_ID']

# êµ¬ê¸€ ì‹œíŠ¸ APIì— ë¡œê·¸ì¸í•˜ê³  ì—°ë™í•  ì‹œíŠ¸(íŒŒì¼)ë¥¼ ì—½ë‹ˆë‹¤.
creds = json.loads(service_account_str)
gc = gspread.service_account_from_dict(creds)
sh = gc.open_by_key(sheet_id)

# ==========================================
# 2. DART API JSON ë°ì´í„° í˜¸ì¶œ í•¨ìˆ˜
# ==========================================
def fetch_dart_json(url, params):
    """ì£¼ì–´ì§„ URLê³¼ íŒŒë¼ë¯¸í„°ë¡œ DART APIë¥¼ í˜¸ì¶œí•´ JSON ê²°ê³¼ë¥¼ íŒë‹¤ìŠ¤ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        res = requests.get(url, params=params)
        if res.status_code == 200:
            data = res.json()
            if data.get('status') == '000' and 'list' in data:
                return pd.DataFrame(data['list'])
    except Exception as e:
        print(f"JSON API ì—ëŸ¬: {e}")
    return pd.DataFrame() # ì—ëŸ¬ ì‹œ ë¹ˆ ë°ì´í„° ë°˜í™˜

# ==========================================
# 3. í•µì‹¬ ì—”ì§„: ê³µì‹œ ì›ë¬¸(XML) ì¡±ì§‘ê²Œ ìŠ¤ìºë„ˆ
# ==========================================
def extract_xml_details(api_key, rcept_no):
    """
    ì ‘ìˆ˜ë²ˆí˜¸(rcept_no)ë¥¼ ë°›ì•„ í•´ë‹¹ ê³µì‹œì˜ ì••ì¶•íŒŒì¼(ZIP)ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ ,
    ê·¸ ì•ˆì˜ XML ë¬¸ì„œë¥¼ ê¹Œì„œ 'ê°€ê²©, í• ì¸ìœ¨, ë‚ ì§œ, íˆ¬ìì'ë¥¼ ì •ë°€í•˜ê²Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {'crtfc_key': api_key, 'rcept_no': rcept_no}
    
    # ë°ì´í„°ë¥¼ ëª» ì°¾ì•˜ì„ ë•Œ ê¸°ë³¸ìœ¼ë¡œ ì¶œë ¥í•  ê°’ë“¤ (ë¹ˆì¹¸)
    extracted = {
        'board_date': '-', 'issue_price': '-', 'base_price': '-', 'discount': '-',
        'pay_date': '-', 'div_date': '-', 'list_date': '-', 'investor': 'ì›ë¬¸ì°¸ì¡°'
    }
    
    try:
        res = requests.get(url, params=params, stream=True)
        if res.status_code == 200:
            # ZIP íŒŒì¼ ë©”ëª¨ë¦¬ìƒì—ì„œ ì••ì¶• í•´ì œ í›„ XML íŒŒì¼ ì°¾ê¸°
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_filename = [name for name in z.namelist() if name.endswith('.xml')][0]
                with z.open(xml_filename) as f:
                    xml_content = f.read().decode('utf-8')
                    soup = BeautifulSoup(xml_content, 'html.parser')
                    
                    # í‘œ(Table) ì•ˆì˜ ë°ì´í„°ê°€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë  ë•Œ ë‹¤ë‹¥ë‹¤ë‹¥ ë¶™ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ê°•ì œ ë„ì–´ì“°ê¸° ì‚½ì…
                    for tag in soup.find_all(['td', 'th', 'p', 'div', 'span']):
                        tag.append(' ')
                        
                    raw_text = soup.get_text(separator=' ', strip=True)
                    # ì •ê·œí™”ëœ í…ìŠ¤íŠ¸: ì—¬ëŸ¬ ê°œì˜ ë„ì–´ì“°ê¸°ë¥¼ í•˜ë‚˜ë¡œ ì••ì¶•
                    clean_text = re.sub(r'\s+', ' ', raw_text)
                    # ì™„ì „ ë¬´ê³µë°± í…ìŠ¤íŠ¸: ë³´ì´ì§€ ì•ŠëŠ” íŠ¹ìˆ˜ê³µë°±ê¹Œì§€ ë°•ì‚´ë‚´ì–´ í• ì¸ìœ¨ ë“± ì •ë°€ ê²€ìƒ‰ì— ì‚¬ìš©
                    text_no_space = re.sub(r'\s+', '', raw_text.replace('\xa0', '').replace('\u200b', ''))
                    
                    # --- [ë°©ì–´ë§‰ ë¡œì§] í•´ë‹¹ ê°’ì´ ì§„ì§œ 'ë¹ˆì¹¸(ë¯¸ì •)'ì¸ì§€ ê²€ì¦ ---
                    def is_empty_value(text_window):
                        # íƒìƒ‰í•œ ë‹¨ì–´ ë°”ë¡œ ë’¤ì— 'ë¯¸ì •', 'í•´ë‹¹ì—†ìŒ' ë“±ì´ ìˆìœ¼ë©´ ì—‰ëš±í•œ ê°’ì„ ì°¾ì§€ ì•Šë„ë¡ ì°¨ë‹¨
                        check_win = re.sub(r'[\s,]', '', text_window)[:15]
                        return bool(re.match(r'^(ë¯¸ì •|í•´ë‹¹ì‚¬í•­ì—†ìŒ|í•´ë‹¹ì—†ìŒ|ê¸°ì¬ìƒëµ)', check_win))

                    # --- 3-1. ê°€ê²©/ê¸ˆì•¡ ì¶”ì¶œê¸° ---
                    def get_price(keyword):
                        for match in re.finditer(keyword, clean_text):
                            window = clean_text[match.end():match.end()+200] # í‚¤ì›Œë“œ ë’¤ 200ê¸€ì ìŠ¤ìº”
                            
                            if is_empty_value(window): return '-' # ë¹ˆì¹¸ì´ë©´ íƒìƒ‰ í¬ê¸°
                                
                            win_clean = re.sub(r'[\s,]', '', window) # '5, 0 0 0' ê°™ì€ ì•…ë„í•œ ë„ì–´ì“°ê¸° ë³µêµ¬
                            # ìˆ«ìë§Œ ì™ ê³¨ë¼ë‚´ê¸° (100 ë¯¸ë§Œì˜ ìˆ«ìëŠ” ì—°ë„/í˜ì´ì§€ë²ˆí˜¸ì¼ ìˆ˜ ìˆì–´ ì œì™¸)
                            nums = re.findall(r'(?<!\d)([1-9]\d{2,})(?!\d)', win_clean)
                            for val_str in nums:
                                val = int(val_str)
                                if val not in [2023, 2024, 2025, 2026, 2027]: # ì—°ë„ê°€ ì•„ë‹ˆë©´ ì½¤ë§ˆ ì°ì–´ì„œ ë°˜í™˜
                                    return f"{val:,}"
                        return '-'
                        
                    extracted['issue_price'] = get_price(r'(?:1\s*ì£¼\s*ë‹¹|í™•\s*ì •|ì˜ˆ\s*ì •|ëª¨\s*ì§‘|ë°œ\s*í–‰|ì‹ \s*ì£¼).{0,10}?ë°œ\s*í–‰\s*ê°€\s*(?:ì•¡)?')
                    extracted['base_price'] = get_price(r'ê¸°\s*ì¤€\s*(?:ì£¼\s*ê°€|ë°œ\s*í–‰\s*ê°€\s*ì•¡|ê°€\s*ì•¡|ë‹¨\s*ê°€|ì£¼\s*ë‹¹\s*ê°€\s*ì•¡)')
                    
                    # --- 3-2. í• ì¸ìœ¨(í• ì¦ë¥ ) íŒ©íŠ¸ ì¶”ì¶œê¸° ---
                    def get_discount():
                        # 'í• ì¸ìœ¨ ë˜ëŠ” í• ì¦ìœ¨(%)' ë“±ì˜ ë‹¨ì–´ë¥¼ ì°¾ìŒ
                        pattern = r'(?:í• ì¸|í• ì¦)[ìœ¨ë¥ ](?:ë˜ëŠ”í• ì¦[ìœ¨ë¥ ]|ë˜ëŠ”í• ì¸[ìœ¨ë¥ ])?(?:\(%\))?'
                        for match in re.finditer(pattern, text_no_space):
                            window = text_no_space[match.end():match.end()+100] # ë’¤ 100ê¸€ì ì´ë‚´ íƒìƒ‰
                            
                            if is_empty_value(window): return "0.00%"
                                
                            # ìˆ«ìì— ë§ˆì´ë„ˆìŠ¤(-), í”ŒëŸ¬ìŠ¤(+)ê°€ ë¶™ì–´ìˆë“  ì•ˆ ë¶™ì–´ìˆë“  ê·¸ëŒ€ë¡œ ì¶”ì¶œ
                            m = re.search(r'^([^\d]{0,15})([+\-]?\d+(?:\.\d+)?)', window)
                            if m:
                                val_str = m.group(2)
                                try: val = float(val_str)
                                except: return '-'
                                
                                if val == 0: return "0.00%"
                                if abs(val) > 100: continue # ë¹„ì •ìƒì ìœ¼ë¡œ í° ìˆ«ìëŠ” ë¬´ì‹œ
                                
                                # ì›ë¬¸ íŒ©íŠ¸ì— ë§ì¶° ë¶€í˜¸ ê²°ì •
                                if '-' in val_str: return f"{val:.2f}%"
                                elif '+' in val_str: return f"{val:+.2f}%"
                                else:
                                    # ë¶€í˜¸ê°€ ì•„ì˜ˆ ì•ˆ ì íŒ ê²½ìš° í…ìŠ¤íŠ¸ ë¬¸ë§¥(í• ì¦/í• ì¸)ìœ¼ë¡œ ìœ ì¶”
                                    if 'í• ì¦' in match.group(0) and 'í• ì¸' not in match.group(0): return f"+{val:.2f}%"
                                    else: return f"-{abs(val):.2f}%"
                        return '-'
                        
                    extracted['discount'] = get_discount()
                    
                    # --- 3-3. ë‚ ì§œ ì¶”ì¶œê¸° ---
                    def get_date(keyword):
                        for match in re.finditer(keyword, clean_text):
                            window = clean_text[match.end():match.end()+200]
                            
                            if is_empty_value(window): return '-'
                                
                            win_clean = window.replace(' ', '')
                            # 2026.04.17 ë˜ëŠ” 2026/04/17 í¬ë§· ëª¨ë‘ ìºì¹˜
                            m = re.search(r'(20[2-3]\d)[\-\.ë…„/]([0-1]?\d)[\-\.ì›”/]([0-3]?\d)', win_clean)
                            if m:
                                y, m_num, d_num = m.groups()
                                return f"{y}ë…„ {m_num.zfill(2)}ì›” {d_num.zfill(2)}ì¼"
                        return '-'
                        
                    extracted['board_date'] = get_date(r'(?:ìµœ\s*ì´ˆ\s*)?ì´\s*ì‚¬\s*íšŒ\s*ê²°\s*ì˜\s*ì¼')
                    extracted['pay_date'] = get_date(r'(ë‚©\s*ì…\s*ì¼|ì£¼\s*ê¸ˆ\s*ë‚©\s*ì…\s*ê¸°\s*ì¼)')
                    extracted['div_date'] = get_date(r'(?:ì‹ \s*ì£¼\s*ì˜\s*)?ë°°\s*ë‹¹\s*ê¸°\s*ì‚°\s*ì¼')
                    # 'ìƒì¥ ì˜ˆì •ì¼' ë¿ë§Œ ì•„ë‹ˆë¼ 'êµë¶€ ì˜ˆì •ì¼' ê°™ì€ ë³€ì¹™ í‘œí˜„ë„ ëŒ€ì‘
                    extracted['list_date'] = get_date(r'(?:ì‹ \s*ì£¼\s*ì˜\s*)?(?:ìƒ\s*ì¥|êµ\s*ë¶€)\s*ì˜ˆ\s*ì •\s*ì¼')
                    
                    # --- 3-4. íˆ¬ìì ì¶”ì¶œ ---
                    if "ì œ3ìë°°ì •" in clean_text: extracted['investor'] = "ì œ3ìë°°ì • (ì›ë¬¸ì°¸ì¡°)"

    except Exception as e:
        print(f"ë¬¸ì„œ XML ì—ëŸ¬ ({rcept_no}): {e}")
        
    return extracted

# ==========================================
# 4. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def to_int(val):
    """ë¹ˆì¹¸ì´ë‚˜ ë¬¸ìê°€ ì„ì¸ ê°’ì„ ì•ˆì „í•˜ê²Œ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    try:
        if pd.isna(val) or str(val).strip() == '': return 0
        return int(float(str(val).replace(',', '').strip()))
    except:
        return 0

# ==========================================
# 5. ë©”ì¸ ë¡œì§: ìœ ìƒì¦ì ë°ì´í„° ìˆ˜ì§‘ ë° ì—…ë°ì´íŠ¸
# ==========================================
def get_and_update_yusang():
    # ìµœê·¼ 12ì¼ê°„ì˜ ë°ì´í„°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=12)).strftime('%Y%m%d')

    print("ìµœê·¼ 12ì¼ ìœ ìƒì¦ì ê³µì‹œ íƒìƒ‰ ì¤‘ (íŒ©íŠ¸ ìŠ¤ìºë„ˆ & ìê°€ ì¹˜ìœ  ëª¨ë“œ ì‘ë™)...")
    
    # DART ëª©ë¡ API í˜¸ì¶œ (last_reprt_at: 'Y' ë¡œ ì •ì •ê³µì‹œì˜ ìµœì¢…ë³¸ë§Œ ê°€ì ¸ì˜´)
    list_url = "https://opendart.fss.or.kr/api/list.json"
    list_params = {
        'crtfc_key': dart_key, 'bgn_de': start_date, 'end_de': end_date, 
        'pblntf_ty': 'B', 'pblntf_detail_ty': 'B001', 'page_count': '100',
        'last_reprt_at': 'Y'
    }
    all_filings = fetch_dart_json(list_url, list_params)

    if all_filings.empty:
        print("ìµœê·¼ ì§€ì • ê¸°ê°„ ë‚´ ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 'ìœ ìƒì¦ìê²°ì •' í‚¤ì›Œë“œê°€ ë“¤ì–´ê°„ ë³´ê³ ì„œë§Œ í•„í„°ë§
    df_filtered = all_filings[all_filings['report_nm'].str.contains('ìœ ìƒì¦ìê²°ì •', na=False)].copy()
    if df_filtered.empty:
        print("â„¹ï¸ ìœ ìƒì¦ì ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df_filtered['corp_cls'] = df_filtered['corp_cls'].fillna('')
        
    corp_codes = df_filtered['corp_code'].unique()
    detail_dfs = []
    
    # í•„í„°ë§ëœ íšŒì‚¬ë“¤ì˜ ê³ ìœ ë²ˆí˜¸ë¥¼ ì´ìš©í•´ 'ìƒì„¸ ì •ë³´ JSON' í˜¸ì¶œ
    for code in corp_codes:
        detail_params = {'crtfc_key': dart_key, 'corp_code': code, 'bgn_de': start_date, 'end_de': end_date}
        df_detail = fetch_dart_json('https://opendart.fss.or.kr/api/piicDecsn.json', detail_params)
        if not df_detail.empty:
            detail_dfs.append(df_detail)
            
    if not detail_dfs:
        print("â„¹ï¸ ìƒì„¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # ë°ì´í„°í”„ë ˆì„ ë³‘í•©: ìƒì„¸ ë°ì´í„° + (ì ‘ìˆ˜ë²ˆí˜¸, ìƒì¥ì‹œì¥, ë³´ê³ ì„œëª…)
    df_combined = pd.concat(detail_dfs, ignore_index=True)
    df_combined = df_combined.drop(columns=['corp_cls'], errors='ignore')
    df_merged = pd.merge(df_combined, df_filtered[['rcept_no', 'corp_cls', 'report_nm']], on='rcept_no', how='left')
    
    # êµ¬ê¸€ ì‹œíŠ¸ì— ì—°ê²°
    worksheet = sh.worksheet('ìœ ìƒì¦ì')
    existing_rcept_nos = worksheet.col_values(21) # 21ë²ˆì§¸ Uì—´(ì ‘ìˆ˜ë²ˆí˜¸)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê¸°ì¡´ ì—¬ë¶€ í™•ì¸
    
    data_to_add = [] # êµ¬ê¸€ ì‹œíŠ¸ì— ìƒˆë¡­ê²Œ ì¶”ê°€ë  í–‰ë“¤ì„ ë‹´ëŠ” ë¦¬ìŠ¤íŠ¸
    cls_map = {'Y': 'ìœ ê°€', 'K': 'ì½”ìŠ¤ë‹¥', 'N': 'ì½”ë„¥ìŠ¤', 'E': 'ê¸°íƒ€'}
    
    # --------------------------------------------------
    # ë°ì´í„° ì¶”ì¶œ ë° ê°€ê³µ ì‹œì‘
    # --------------------------------------------------
    for _, row in df_merged.iterrows():
        rcept_no = str(row.get('rcept_no', ''))
        corp_name = row.get('corp_name', '')
        report_nm = row.get('report_nm', '') 
        
        # ì•ì„œ ë§Œë“  XML ìŠ¤ìºë„ˆ(extract_xml_details)ë¥¼ ê°€ë™
        xml_data = extract_xml_details(dart_key, rcept_no)
        
        market = cls_map.get(row.get('corp_cls', ''), 'ê¸°íƒ€')
        method = row.get('ic_mthn', '')
        
        ostk = to_int(row.get('nstk_ostk_cnt'))
        estk = to_int(row.get('nstk_estk_cnt'))
        new_shares = ostk + estk
        product = "ë³´í†µì£¼" if ostk > 0 else "ê¸°íƒ€ì£¼"
        
        old_ostk = to_int(row.get('bfic_tisstk_ostk'))
        old_estk = to_int(row.get('bfic_tisstk_estk'))
        old_shares = old_ostk + old_estk
        
        new_shares_str = f"{new_shares:,}"
        old_shares_str = f"{old_shares:,}"
        
        ratio = f"{(new_shares / old_shares * 100):.2f}%" if old_shares > 0 else "-"
        
        fclt = to_int(row.get('fdpp_fclt'))
        bsninh = to_int(row.get('fdpp_bsninh'))
        op = to_int(row.get('fdpp_op'))
        dtrp = to_int(row.get('fdpp_dtrp'))
        ocsa = to_int(row.get('fdpp_ocsa'))
        etc = to_int(row.get('fdpp_etc'))
        
        total_amt = fclt + bsninh + op + dtrp + ocsa + etc
        total_amt_uk = f"{(total_amt / 100000000):,.2f}" if total_amt > 0 else "0.00"
        
        # ìê¸ˆì¡°ë‹¬ ëª©ì (ìš©ë„)ì„ ì½¤ë§ˆë¡œ ì—°ê²°
        purposes = []
        if fclt > 0: purposes.append("ì‹œì„¤")
        if bsninh > 0: purposes.append("ì˜ì—…ì–‘ìˆ˜")
        if op > 0: purposes.append("ìš´ì˜")
        if dtrp > 0: purposes.append("ì±„ë¬´ìƒí™˜")
        if ocsa > 0: purposes.append("íƒ€ë²•ì¸ì¦ê¶Œ")
        if etc > 0: purposes.append("ê¸°íƒ€")
        purpose_str = ", ".join(purposes)
        
        link = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
        
        # ìµœì¢…ì ìœ¼ë¡œ êµ¬ê¸€ ì‹œíŠ¸ 1í–‰ì„ êµ¬ì„±í•  21ì¹¸ì˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        new_row = [
            corp_name,                           # 1. íšŒì‚¬ëª…
            report_nm,                           # 2. ë³´ê³ ì„œëª…
            market,                              # 3. ìƒì¥ì‹œì¥
            xml_data['board_date'],              # 4. ìµœì´ˆ ì´ì‚¬íšŒê²°ì˜ì¼
            method,                              # 5. ì¦ìë°©ì‹
            product,                             # 6. ë°œí–‰ìƒí’ˆ
            new_shares_str,                      # 7. ì‹ ê·œë°œí–‰ì£¼ì‹ìˆ˜
            xml_data.get('issue_price', '-'),    # 8. í™•ì •ë°œí–‰ê°€(ì›)
            xml_data.get('base_price', '-'),     # 9. ê¸°ì¤€ì£¼ê°€
            total_amt_uk,                        # 10. í™•ì •ë°œí–‰ê¸ˆì•¡(ì–µì›)
            xml_data.get('discount', '-'),       # 11. í• ì¸(í• ì¦ë¥ )
            old_shares_str,                      # 12. ì¦ìì „ ì£¼ì‹ìˆ˜
            ratio,                               # 13. ì¦ìë¹„ìœ¨
            xml_data['pay_date'],                # 14. ë‚©ì…ì¼
            xml_data['div_date'],                # 15. ë°°ë‹¹ê¸°ì‚°ì¼
            xml_data['list_date'],               # 16. ì‹ ì£¼ì˜ ìƒì¥ ì˜ˆì •ì¼
            xml_data['board_date'],              # 17. ì´ì‚¬íšŒê²°ì˜ì¼
            purpose_str,                         # 18. ìê¸ˆìš©ë„
            xml_data['investor'],                # 19. íˆ¬ìì
            link,                                # 20. ë§í¬
            rcept_no                             # 21. ì ‘ìˆ˜ë²ˆí˜¸ (ê¸°ì¤€ ì‹ë³„ì)
        ]
        
        # --------------------------------------------------
        # êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ (ìê°€ ì¹˜ìœ  ë° ì‹ ê·œ ì¶”ê°€)
        # --------------------------------------------------
        # 1. ì‹œíŠ¸ì— ë™ì¼í•œ ì ‘ìˆ˜ë²ˆí˜¸ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° -> í•´ë‹¹ í–‰ì„ ìµœì‹  ë°ì´í„°ë¡œ 'ë®ì–´ì“°ê¸°'
        if rcept_no in existing_rcept_nos:
            row_idx = existing_rcept_nos.index(rcept_no) + 1 # 1ë²ˆ í–‰ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1
            try:
                # gspread ë²„ì „ì— ë§ê²Œ ìœ ì—°í•œ ì—…ë°ì´íŠ¸ ì²˜ë¦¬
                worksheet.update(range_name=f'A{row_idx}:U{row_idx}', values=[new_row])
            except TypeError:
                worksheet.update(f'A{row_idx}:U{row_idx}', [new_row])
            print(f" ğŸ”„ {corp_name}: ê¸°ì¡´ ì˜¤ë¥˜ ë°ì´í„° ì¬ìŠ¤ìº” ë° ì™„ë²½ ë®ì–´ì“°ê¸° ì™„ë£Œ! (í–‰: {row_idx})")
            
        # 2. ì‹œíŠ¸ì— ì—†ëŠ” ìƒˆë¡œìš´ ì ‘ìˆ˜ë²ˆí˜¸ì¸ ê²½ìš° -> ì‹ ê·œ ì¶”ê°€ ëŒ€ê¸°ì—´ì— ë‹´ê¸°
        else:
            print(f" ğŸ†• {corp_name}: ì‹ ê·œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
            data_to_add.append(new_row)
        
    # ë£¨í”„ ì¢…ë£Œ í›„, ì‹ ê·œ ì¶”ê°€í•  ë°ì´í„°ê°€ ìˆë‹¤ë©´ í•œêº¼ë²ˆì— ë§¨ ë°‘ì— ì‚½ì…
    if data_to_add:
        worksheet.append_rows(data_to_add)
        print(f"âœ… ìœ ìƒì¦ì: ì‹ ê·œ ê³µì‹œ {len(data_to_add)}ê±´ ì¶”ê°€ ì™„ë£Œ!")
    else:
        print("âœ… ìœ ìƒì¦ì: ìƒˆ ê³µì‹œëŠ” ì—†ìœ¼ë©°, ê¸°ì¡´ ê³µì‹œë“¤ì˜ ì¬ê²€í†  ë° ì˜¤ë¥˜ ìˆ˜ì •ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    get_and_update_yusang()
