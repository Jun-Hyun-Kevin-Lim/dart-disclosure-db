import os
import json
import gspread
import pandas as pd
import requests
import zipfile
import io
import re
from bs4 import BeautifulSoup
from datetime import datetime, timedelta

# ==========================================
# 1. ì´ˆê¸° ì…‹íŒ…: API í‚¤ì™€ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì¤€ë¹„
# ==========================================
# ê¹ƒí—ˆë¸Œ ì‹œí¬ë¦¿(ë¹„ë°€ì°½ê³ )ì— ìˆ¨ê²¨ë‘” DART API í‚¤ì™€ êµ¬ê¸€ ì‹œíŠ¸ ì ‘ì† ë¹„ë°€ë²ˆí˜¸ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
dart_key = os.environ['DART_API_KEY']
service_account_str = os.environ['GOOGLE_CREDENTIALS_JSON']
sheet_id = os.environ['GOOGLE_SHEET_ID'] # ìš°ë¦¬ê°€ ì €ì¥í•  êµ¬ê¸€ ì—‘ì…€ íŒŒì¼ì˜ ê³ ìœ  ì£¼ì†Œ

# ê°€ì ¸ì˜¨ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì´ìš©í•´ êµ¬ê¸€ ì‹œíŠ¸ì— ë¡œê·¸ì¸(ì¸ì¦)ì„ í•©ë‹ˆë‹¤.
creds = json.loads(service_account_str)
gc = gspread.service_account_from_dict(creds)
sh = gc.open_by_key(sheet_id) # êµ¬ê¸€ ì‹œíŠ¸ íŒŒì¼ì„ ì—½ë‹ˆë‹¤.

# ==========================================
# 2. DART ëª©ë¡ ê°€ì ¸ì˜¤ê¸° í•¨ìˆ˜ (ê¸°ë³¸ ì •ë³´ ìŠ¤ìºë„ˆ)
# ==========================================
def fetch_dart_json(url, params):
    """
    DART(ì „ìê³µì‹œì‹œìŠ¤í…œ)ì— "ìµœê·¼ ìœ ìƒì¦ì ëª©ë¡ ì¢€ ì¤˜!" ë¼ê³  ìš”ì²­í•´ì„œ
    ë°›ì•„ì˜¨ ê²°ê³¼ë¬¼(JSON í˜•ì‹)ì„ ì—‘ì…€ í‘œ(ë°ì´í„°í”„ë ˆì„)ì²˜ëŸ¼ ì˜ˆì˜ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    try:
        res = requests.get(url, params=params) # ì¸í„°ë„· ì£¼ì†Œë¡œ ë°ì´í„° ë‹¬ë¼ê³  ìš”ì²­!
        if res.status_code == 200: # 200ì€ 'ì •ìƒì ìœ¼ë¡œ ì˜ ë°›ì•˜ìŒ'ì„ ëœ»í•©ë‹ˆë‹¤.
            data = res.json()
            # ë°ì´í„°ê°€ ë¹„ì–´ìˆì§€ ì•Šê³  ì˜ ì™”ìœ¼ë©´ í‘œ í˜•íƒœë¡œ ë°”ê¿”ì„œ ëŒë ¤ì¤ë‹ˆë‹¤.
            if data.get('status') == '000' and 'list' in data:
                return pd.DataFrame(data['list'])
    except Exception as e:
        print(f"JSON API ì—ëŸ¬: {e}") # ì¸í„°ë„·ì´ ëŠê¸°ê±°ë‚˜ ì—ëŸ¬ê°€ ë‚˜ë©´ ì´ìœ ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    return pd.DataFrame() # ì‹¤íŒ¨í•˜ë©´ ë¹ˆ í‘œë¥¼ ëŒë ¤ì¤ë‹ˆë‹¤.

# ==========================================
# 3. ğŸ’¡ í•µì‹¬ ì—”ì§„: ê³µì‹œ ì›ë¬¸(í‘œ êµ¬ì¡°) ì¡±ì§‘ê²Œ ìŠ¤ìºë„ˆ
# ==========================================
def extract_xml_details(api_key, rcept_no):
    """
    ì ‘ìˆ˜ë²ˆí˜¸ë¥¼ ë°›ì•„ì„œ í•´ë‹¹ ê³µì‹œì˜ ì§„ì§œ ì›ë³¸ ë¬¸ì„œ(XML) ì••ì¶•íŒŒì¼ì„ ë‹¤ìš´ë°›ì€ ë’¤,
    ìš°ë¦¬ê°€ ì›í•˜ëŠ” 'ê°€ê²©, í• ì¸ìœ¨, ë‚ ì§œ'ë¥¼ í‘œ(Table) êµ¬ì¡°ì— ë§ì¶°ì„œ ì™ì™ ë½‘ì•„ë‚´ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    """
    # ì›ë¬¸ ë‹¤ìš´ë¡œë“œ ì£¼ì†Œ
    url = "https://opendart.fss.or.kr/api/document.xml"
    params = {'crtfc_key': api_key, 'rcept_no': rcept_no}
    
    # ë°ì´í„°ë¥¼ ëª» ì°¾ì•˜ì„ ë•Œ ê¸°ë³¸ìœ¼ë¡œ ì¶œë ¥í•  ê°’ë“¤ (ê¸°ë³¸ê°’ì€ ë¹ˆì¹¸ì¸ '-'ë¡œ ì„¤ì •)
    extracted = {
        'board_date': '-', 'issue_price': '-', 'base_price': '-', 'discount': '-',
        'pay_date': '-', 'div_date': '-', 'list_date': '-', 'investor': 'ì›ë¬¸ì°¸ì¡°'
    }
    
    try:
        res = requests.get(url, params=params, stream=True) # ì••ì¶•íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        if res.status_code == 200:
            # ZIP ì••ì¶•íŒŒì¼ì„ í’€ì–´ì„œ ì•ˆì— ìˆëŠ” XML ë¬¸ì„œë§Œ êº¼ëƒ…ë‹ˆë‹¤.
            with zipfile.ZipFile(io.BytesIO(res.content)) as z:
                xml_filename = [name for name in z.namelist() if name.endswith('.xml')][0]
                with z.open(xml_filename) as f:
                    xml_content = f.read().decode('utf-8')
                    # ì»´í“¨í„°ê°€ ì½ê¸° í¸í•˜ê²Œ BeautifulSoup ì´ë¼ëŠ” ë„êµ¬ë¡œ ë¬¸ì„œë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
                    soup = BeautifulSoup(xml_content, 'html.parser')
                    
                    # ë½‘ì•„ë‚¸ ë‚ ê²ƒì˜ ë°ì´í„°ë¥¼ ì„ì‹œë¡œ ë‹´ì•„ë‘˜ ë°”êµ¬ë‹ˆ
                    raw_data = {}
                    
                    # ğŸ’¡ [í‘œ êµ¬ì¡° ë¶„ì„] ë¬¸ì„œ ì•ˆì— ìˆëŠ” ëª¨ë“  í‘œì˜ 'ì¤„(tr)'ì„ í•˜ë‚˜ì”© ì½ì–´ë´…ë‹ˆë‹¤.
                    for tr in soup.find_all('tr'):
                        cells = tr.find_all(['th', 'td']) # í•œ ì¤„ì— ìˆëŠ” ëª¨ë“  'ì¹¸(ì…€)'ë“¤
                        
                        # ê° ì¹¸ì„ ì™¼ìª½ë¶€í„° ì˜¤ë¥¸ìª½ìœ¼ë¡œ í•˜ë‚˜ì”© í™•ì¸í•©ë‹ˆë‹¤.
                        for i in range(len(cells)):
                            # í˜„ì¬ ì¹¸ì˜ ê¸€ìë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. (ì˜ˆ: "ê¸°ì¤€ì£¼ê°€")
                            header_raw = cells[i].get_text(strip=True)
                            # ë„ì–´ì“°ê¸°ë¥¼ ì „ë¶€ ì—†ì• ì„œ ë¹½ë¹½í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. (ê²€ìƒ‰ì„ ì‰½ê²Œ í•˜ê¸° ìœ„í•´)
                            header_clean = re.sub(r'\s+', '', header_raw.replace('\xa0', ''))
                            
                            # ë§Œì•½ í˜„ì¬ ì¹¸ ì˜¤ë¥¸ìª½ì— ë°ì´í„°ê°€ ë“¤ì–´ê°ˆ ì¹¸ì´ ë‚¨ì•„ìˆë‹¤ë©´?
                            if i + 1 < len(cells):
                                # ë¬´ì¡°ê±´ 'í˜„ì¬ ì¹¸ì˜ ì˜¤ë¥¸ìª½ ì¹¸'ì— ìˆëŠ” ê¸€ìë§Œ ê¸ì–´ì˜µë‹ˆë‹¤! (ë‹¤ë¥¸ ì¤„ ì¹¨ë²” ë°©ì§€)
                                val_raw = " ".join([c.get_text(separator=' ', strip=True) for c in cells[i+1:]])
                                
                                # ë§Œì•½ ì™¼ìª½ ì¹¸ ì œëª©ì´ 'ë°œí–‰ê°€ì•¡'ê³¼ ê´€ë ¨ëœ ë‹¨ì–´ë¼ë©´, ì˜¤ë¥¸ìª½ ì¹¸ì˜ ê°’ì„ ë°”êµ¬ë‹ˆì— ë‹´ìŠµë‹ˆë‹¤.
                                if 'issue_price' not in raw_data and re.search(r'(1ì£¼ë‹¹|í™•ì •|ì˜ˆì •|ëª¨ì§‘|ë°œí–‰|ì‹ ì£¼).*ë°œí–‰ê°€ì•¡', header_clean):
                                    raw_data['issue_price'] = val_raw
                                # ì œëª©ì´ 'ê¸°ì¤€ì£¼ê°€'ë‚˜ 'ê¸°ì¤€ë‹¨ê°€'ë¼ë©´?
                                elif 'base_price' not in raw_data and re.search(r'^ê¸°ì¤€(ì£¼ê°€|ë°œí–‰ê°€ì•¡|ê°€ì•¡|ë‹¨ê°€|ì£¼ë‹¹ê°€ì•¡)', header_clean):
                                    raw_data['base_price'] = val_raw
                                # ì œëª©ì´ 'í• ì¸ìœ¨'ì´ë‚˜ 'í• ì¦ë¥ 'ì´ë¼ë©´?
                                elif 'discount' not in raw_data and re.search(r'(í• ì¸|í• ì¦)[ìœ¨ë¥ ]', header_clean):
                                    raw_data['discount'] = val_raw
                                    raw_data['discount_header'] = header_clean # ë‚˜ì¤‘ì— ë¶€í˜¸ íŒë³„ì„ ìœ„í•´ ì œëª©ë„ ê°™ì´ ì €ì¥
                                # ì œëª©ì´ 'ì´ì‚¬íšŒê²°ì˜ì¼' ì´ë¼ë©´?
                                elif 'board_date' not in raw_data and re.search(r'(ìµœì´ˆ)?ì´ì‚¬íšŒê²°ì˜ì¼', header_clean):
                                    raw_data['board_date'] = val_raw
                                # ì œëª©ì´ 'ë‚©ì…ì¼' ì´ë¼ë©´?
                                elif 'pay_date' not in raw_data and re.search(r'(ë‚©ì…ì¼|ì£¼ê¸ˆë‚©ì…ê¸°ì¼)', header_clean):
                                    raw_data['pay_date'] = val_raw
                                # ì œëª©ì´ 'ë°°ë‹¹ê¸°ì‚°ì¼' ì´ë¼ë©´?
                                elif 'div_date' not in raw_data and re.search(r'(ì‹ ì£¼ì˜)?ë°°ë‹¹ê¸°ì‚°ì¼', header_clean):
                                    raw_data['div_date'] = val_raw
                                # ì œëª©ì´ 'ìƒì¥ ì˜ˆì •ì¼' ì´ë¼ë©´?
                                elif 'list_date' not in raw_data and re.search(r'(ì‹ ì£¼ê¶Œêµë¶€ì˜ˆì •ì¼|ì‹ ì£¼ì˜ìƒì¥ì˜ˆì •ì¼|ìƒì¥ì˜ˆì •ì¼|ì‹ ì£¼ìƒì¥ì˜ˆì •ì¼)', header_clean):
                                    raw_data['list_date'] = val_raw

                    # --- [í´ë¦¬ë‹ 1] ë½‘ì•„ì˜¨ ê°€ê²© ë°ì´í„° ì˜ˆì˜ê²Œ ë‹¤ë“¬ê¸° ---
                    def clean_price(text):
                        if not text: return '-' # ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆì¹¸(-) ë°˜í™˜
                        text_clean = re.sub(r'[\s,ì›]', '', text) # ë„ì–´ì“°ê¸°, ì‰¼í‘œ, 'ì›' ê¸€ì ì „ë¶€ ì œê±°
                        # 'ë¯¸ì •'ì´ë‚˜ 'í•´ë‹¹ì—†ìŒ'ì´ë¼ê³  ì í˜€ìˆìœ¼ë©´ ì–µì§€ë¡œ ìˆ«ì ì•ˆ ì°¾ê³  ë¹ˆì¹¸ ì²˜ë¦¬!
                        if re.search(r'^(ë¯¸ì •|í•´ë‹¹ì—†ìŒ|ê¸°ì¬ìƒëµ|-)', text_clean): return '-'
                        
                        # 100 ì´ìƒì˜ ì§„ì§œ ìˆ«ìë§Œ ì°¾ì•„ë‚´ê¸°
                        nums = re.findall(r'(?<!\d)([1-9]\d{2,})(?!\d)', text_clean)
                        for val_str in nums:
                            val = int(val_str)
                            # 2024, 2025 ê°™ì€ ì—°ë„ëŠ” ê°€ê²©ì´ ì•„ë‹ˆë‹ˆê¹Œ ë¬´ì‹œí•˜ê³ , ì§„ì§œ ê°€ê²©ì´ë©´ ì½¤ë§ˆ(,) ì°ì–´ì„œ ë°˜í™˜
                            if val not in [2023, 2024, 2025, 2026, 2027]:
                                return f"{val:,}"
                        return '-'
                        
                    # --- [í´ë¦¬ë‹ 2] ë½‘ì•„ì˜¨ ë‚ ì§œ ë°ì´í„° ì˜ˆì˜ê²Œ ë‹¤ë“¬ê¸° ---
                    def clean_date(text):
                        if not text: return '-'
                        text_clean = re.sub(r'\s+', '', text)
                        if re.search(r'^(ë¯¸ì •|í•´ë‹¹ì—†ìŒ|ê¸°ì¬ìƒëµ|-)', text_clean): return '-'
                        
                        # 2026.04.17 ì´ë‚˜ 2026/04/17 ê°™ì€ ëª¨ì–‘ì˜ ë‚ ì§œë¥¼ ì°¾ì•„ì„œ '2026ë…„ 04ì›” 17ì¼' ëª¨ì–‘ìœ¼ë¡œ í†µì¼
                        m = re.search(r'(20[2-3]\d)[\-\.ë…„/]([0-1]?\d)[\-\.ì›”/]([0-3]?\d)', text_clean)
                        if m:
                            y, m_num, d_num = m.groups()
                            return f"{y}ë…„ {m_num.zfill(2)}ì›” {d_num.zfill(2)}ì¼" # 1ì›”ì„ 01ì›”ë¡œ ë§ì¶°ì¤Œ(zfill)
                        return '-'
                        
                    # --- [í´ë¦¬ë‹ 3] ë½‘ì•„ì˜¨ í• ì¸ìœ¨(í• ì¦ë¥ ) íŒ©íŠ¸ ì²´í¬ ë° ë‹¤ë“¬ê¸° ---
                    def clean_discount(text, issue_p, base_p, header_text):
                        if not text: return '-'
                        text_clean = re.sub(r'\s+', '', text)
                        if re.search(r'^(ë¯¸ì •|í•´ë‹¹ì‚¬í•­ì—†ìŒ|í•´ë‹¹ì—†ìŒ|ê¸°ì¬ìƒëµ)', text_clean): return "0.00%"
                        
                        # íŒ©íŠ¸ ì²´í¬ë¥¼ ìœ„í•œ ë³´ì¡° ìˆ˜ë‹¨: ë°œí–‰ê°€ì™€ ê¸°ì¤€ì£¼ê°€ë¥¼ ì‚´ì§ ë¹„êµí•´ë´…ë‹ˆë‹¤.
                        math_sign = 0
                        if issue_p != '-' and base_p != '-':
                            try:
                                i_v = float(issue_p.replace(',', ''))
                                b_v = float(base_p.replace(',', ''))
                                if b_v > 0:
                                    if i_v > b_v: math_sign = 1    # ë¹„ì‹¸ë©´ í• ì¦(+)
                                    elif i_v < b_v: math_sign = -1 # ì‹¸ë©´ í• ì¸(-)
                            except: pass
                            
                        # ì˜¤ë¥¸ìª½ ì¹¸ì— ì íŒ ìˆ«ìì™€ ë¶€í˜¸(+,-)ë¥¼ ì™ ë½‘ì•„ì˜µë‹ˆë‹¤.
                        m = re.search(r'([+\-]?\d+(?:\.\d+)?)', text_clean)
                        if m:
                            val_str = m.group(1)
                            try: val = float(val_str)
                            except: return '-'
                            
                            if val == 0: return "0.00%"
                            if abs(val) > 100: return '-' # í˜ì´ì§€ ë²ˆí˜¸ ê°™ì€ ì“°ë ˆê¸°ê°’ ë¬´ì‹œ
                            
                            # ë¶€í˜¸ íŒë³„!
                            if math_sign != 0:
                                return f"{abs(val) * math_sign:+.2f}%" # í™•ì‹¤í•˜ë©´ ìˆ˜í•™ì  íŒ©íŠ¸ ë”°ë¥´ê¸°
                            else:
                                if '-' in val_str: return f"{val:.2f}%" # ë§ˆì´ë„ˆìŠ¤ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥
                                elif '+' in val_str: return f"{val:+.2f}%" # í”ŒëŸ¬ìŠ¤ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥
                                else:
                                    # ê¸°í˜¸ê°€ ì—†ìœ¼ë©´ í‘œ ì™¼ìª½ ì œëª©ì— ì íŒ 'í• ì¦'/'í• ì¸' ë‹¨ì–´ ë³´ê³  ìœ ì¶”
                                    if 'í• ì¦' in header_text and 'í• ì¸' not in header_text: return f"+{val:.2f}%"
                                    else: return f"-{abs(val):.2f}%" # ì›¬ë§Œí•˜ë©´ í• ì¸(-) ì²˜ë¦¬
                        
                        if text_clean == '-': return "0.00%"
                        return '-'

                    # ìœ„ì—ì„œ ë§Œë“  í´ë¦¬ë‹ ê¸°ê³„ë¥¼ ëŒë ¤ì„œ ìµœì¢… ë°ì´í„°ë¥¼ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ ë°”êµ¬ë‹ˆ(extracted)ì— ë„£ìŠµë‹ˆë‹¤.
                    extracted['issue_price'] = clean_price(raw_data.get('issue_price'))
                    extracted['base_price'] = clean_price(raw_data.get('base_price'))
                    extracted['discount'] = clean_discount(raw_data.get('discount'), extracted['issue_price'], extracted['base_price'], raw_data.get('discount_header', ''))
                    extracted['board_date'] = clean_date(raw_data.get('board_date'))
                    extracted['pay_date'] = clean_date(raw_data.get('pay_date'))
                    extracted['div_date'] = clean_date(raw_data.get('div_date'))
                    extracted['list_date'] = clean_date(raw_data.get('list_date'))
                    
                    # íˆ¬ìì ì¶”ì¶œ: ë¬¸ì„œ ì „ì²´ì— 'ì œ3ìë°°ì •'ì´ë¼ëŠ” ë§ì´ ìˆìœ¼ë©´ ë¬´ì¡°ê±´ ì ì–´ì¤Œ
                    full_text = soup.get_text(separator=' ', strip=True).replace(' ', '')
                    if "ì œ3ìë°°ì •" in full_text: extracted['investor'] = "ì œ3ìë°°ì • (ì›ë¬¸ì°¸ì¡°)"

    except Exception as e:
        print(f"ë¬¸ì„œ XML ì—ëŸ¬ ({rcept_no}): {e}") # ì¤‘ê°„ì— ë¬¸ì„œ ì—´ë‹¤ê°€ í„°ì§€ë©´ ì—ëŸ¬ í‘œì‹œ
        
    return extracted # ê½‰ê½‰ ì±„ì›Œì§„ 8ê°œ ë°ì´í„°ë¥¼ ëŒë ¤ì¤ë‹ˆë‹¤.

# ==========================================
# 4. ìˆ«ì ë³€í™˜ ë³´ì¡° í•¨ìˆ˜
# ==========================================
def to_int(val):
    """í‘œì— ìˆëŠ” ê¸€ì(ì˜ˆ: 1,000)ë¥¼ ì§„ì§œ ì»´í“¨í„° ìˆ«ì(1000)ë¡œ ë°”ê¿”ì„œ ë§ì…ˆ ëº„ì…ˆì´ ê°€ëŠ¥í•˜ê²Œ í•´ì¤ë‹ˆë‹¤."""
    try:
        if pd.isna(val) or str(val).strip() == '': return 0
        return int(float(str(val).replace(',', '').strip()))
    except:
        return 0 # ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ 0

# ==========================================
# 5. ë©”ì¸ ë¡œì§: ìœ ìƒì¦ì ë°ì´í„° ìˆ˜ì§‘ & êµ¬ê¸€ ì‹œíŠ¸ ì—…ë°ì´íŠ¸
# ==========================================
def get_and_update_yusang():
    # 1. ë‚ ì§œ ì„¤ì •: ì˜¤ëŠ˜ë¶€í„° 12ì¼ ì „ê¹Œì§€ì˜ ê³µì‹œë§Œ ë’¤ì ¸ë´…ë‹ˆë‹¤.
    end_date = datetime.now().strftime('%Y%m%d')
    start_date = (datetime.now() - timedelta(days=12)).strftime('%Y%m%d')

    print("ìµœê·¼ 12ì¼ ìœ ìƒì¦ì ê³µì‹œ íƒìƒ‰ ì¤‘ (í‘œ êµ¬ì¡° ë¶„ì„ & ë®ì–´ì“°ê¸° ëª¨ë“œ ì‘ë™)...")
    
    # 2. DARTì— "12ì¼ì¹˜ ê³µì‹œ ëª©ë¡ ë‹¤ ê°€ì ¸ì™€!" ë¼ê³  ìš”ì²­í•©ë‹ˆë‹¤.
    # last_reprt_at: 'Y' ì„¤ì •ìœ¼ë¡œ ì˜›ë‚  êº¼ ë§ê³  'ê°€ì¥ ìµœì‹  ì •ì •ë³´ê³ ì„œ'ë§Œ ê°€ì ¸ì˜¤ê²Œ í•©ë‹ˆë‹¤.
    list_url = "https://opendart.fss.or.kr/api/list.json"
    list_params = {
        'crtfc_key': dart_key, 'bgn_de': start_date, 'end_de': end_date, 
        'pblntf_ty': 'B', 'pblntf_detail_ty': 'B001', 'page_count': '100',
        'last_reprt_at': 'Y' 
    }
    all_filings = fetch_dart_json(list_url, list_params)

    # ëª©ë¡ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
    if all_filings.empty:
        print("ìµœê·¼ ì§€ì • ê¸°ê°„ ë‚´ ì£¼ìš”ì‚¬í•­ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. ê°€ì ¸ì˜¨ ëª©ë¡ ì¤‘ì—ì„œ ì œëª©ì— 'ìœ ìƒì¦ìê²°ì •'ì´ ë“¤ì–´ê°„ ê²ƒë§Œ ì²´ì— ê±¸ëŸ¬ëƒ…ë‹ˆë‹¤.
    df_filtered = all_filings[all_filings['report_nm'].str.contains('ìœ ìƒì¦ìê²°ì •', na=False)].copy()
    if df_filtered.empty:
        print("â„¹ï¸ ìœ ìƒì¦ì ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    df_filtered['corp_cls'] = df_filtered['corp_cls'].fillna('')
        
    # 4. ê±¸ëŸ¬ì§„ íšŒì‚¬ë“¤ì˜ ê³ ìœ ë²ˆí˜¸ë¥¼ ëª¨ì•„ì„œ, ì´ë²ˆì—” "ìœ ìƒì¦ì ìƒì„¸ ë°ì´í„° ì¤˜!" ë¼ê³  ë‹¤ì‹œ ìš”ì²­í•©ë‹ˆë‹¤.
    corp_codes = df_filtered['corp_code'].unique()
    detail_dfs = []
    for code in corp_codes:
        detail_params = {'crtfc_key': dart_key, 'corp_code': code, 'bgn_de': start_date, 'end_de': end_date}
        df_detail = fetch_dart_json('https://opendart.fss.or.kr/api/piicDecsn.json', detail_params)
        if not df_detail.empty:
            detail_dfs.append(df_detail)
            
    if not detail_dfs:
        print("â„¹ï¸ ìƒì„¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # ìƒì„¸ ë°ì´í„°ë“¤ì„ ë‹¤ ëª¨ì•„ì„œ í•˜ë‚˜ë¡œ í¼ì§í•˜ê²Œ í•©ì¹©ë‹ˆë‹¤.
    df_combined = pd.concat(detail_dfs, ignore_index=True)
    df_combined = df_combined.drop(columns=['corp_cls'], errors='ignore')
    
    # ì•„ê¹Œ ê°€ì ¸ì˜¨ ëª©ë¡ ë°ì´í„°(ë³´ê³ ì„œëª… ë“±)ì™€ ìƒì„¸ ë°ì´í„°ë¥¼ 'ì ‘ìˆ˜ë²ˆí˜¸'ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì§ë§ì¶° í•©ì¹©ë‹ˆë‹¤.
    df_merged = pd.merge(df_combined, df_filtered[['rcept_no', 'corp_cls', 'report_nm']], on='rcept_no', how='left')
    
    # 5. êµ¬ê¸€ ì‹œíŠ¸ì˜ 'ìœ ìƒì¦ì' íƒ­ì„ ì—½ë‹ˆë‹¤.
    worksheet = sh.worksheet('ìœ ìƒì¦ì')
    # 21ë²ˆì§¸ ì¹¸(Uì—´)ì— ì í˜€ìˆëŠ” ê¸°ì¡´ ê³µì‹œë“¤ì˜ ì ‘ìˆ˜ë²ˆí˜¸ë¥¼ ì „ë¶€ ê°€ì ¸ì™€ì„œ ê¸°ì–µí•´ë‘¡ë‹ˆë‹¤. (ì¤‘ë³µ ë°©ì§€ & ë®ì–´ì“°ê¸° ìš©ë„)
    existing_rcept_nos = worksheet.col_values(21) 
    
    data_to_add = [] # ì™„ì „ ìƒˆë¡œìš´ ê³µì‹œë¥¼ ë‹´ì„ ëŒ€ê¸°ì—´
    cls_map = {'Y': 'ìœ ê°€', 'K': 'ì½”ìŠ¤ë‹¥', 'N': 'ì½”ë„¥ìŠ¤', 'E': 'ê¸°íƒ€'}
    
    # 6. í•©ì³ì§„ ë°ì´í„°ë¥¼ í•œ ì¤„ì”© ì½ìœ¼ë©´ì„œ êµ¬ê¸€ ì‹œíŠ¸ì— ë„£ì„ ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.
    for _, row in df_merged.iterrows():
        rcept_no = str(row.get('rcept_no', ''))
        corp_name = row.get('corp_name', '')
        report_nm = row.get('report_nm', '') 
        
        # ğŸ’¡ [í•„ì‚´ê¸° ì¶œë™] í‘œ êµ¬ì¡°(DOM) ìŠ¤ìºë„ˆë¥¼ ë³´ë‚´ì„œ ì›ë³¸ íŒ©íŠ¸ 8ê°œë¥¼ ìºì˜µë‹ˆë‹¤!
        xml_data = extract_xml_details(dart_key, rcept_no)
        
        # ë‚¨ì€ ë°ì´í„°ë“¤ ê³„ì‚°í•˜ê¸° (ë³´í†µì£¼, ê¸°íƒ€ì£¼ í•©ì¹˜ê¸° ë“±)
        market = cls_map.get(row.get('corp_cls', ''), 'ê¸°íƒ€')
        method = row.get('ic_mthn', '')
        
        ostk = to_int(row.get('nstk_ostk_cnt'))
        estk = to_int(row.get('nstk_estk_cnt'))
        new_shares = ostk + estk # ì‹ ê·œë°œí–‰ì£¼ì‹ìˆ˜ = ë³´í†µì£¼ + ê¸°íƒ€ì£¼
        product = "ë³´í†µì£¼" if ostk > 0 else "ê¸°íƒ€ì£¼"
        
        old_ostk = to_int(row.get('bfic_tisstk_ostk'))
        old_estk = to_int(row.get('bfic_tisstk_estk'))
        old_shares = old_ostk + old_estk # ì¦ìì „ ì£¼ì‹ìˆ˜ = ë³´í†µì£¼ + ê¸°íƒ€ì£¼
        
        new_shares_str = f"{new_shares:,}"
        old_shares_str = f"{old_shares:,}"
        
        # ì¦ìë¹„ìœ¨ ê³„ì‚°: (ì‹ ê·œë°œí–‰ì£¼ì‹ìˆ˜ / ì¦ìì „ ì£¼ì‹ìˆ˜) * 100
        ratio = f"{(new_shares / old_shares * 100):.2f}%" if old_shares > 0 else "-"
        
        # ìê¸ˆ ìš©ë„ë³„ ê¸ˆì•¡ë“¤ ê°€ì ¸ì˜¤ê¸°
        fclt = to_int(row.get('fdpp_fclt'))
        bsninh = to_int(row.get('fdpp_bsninh'))
        op = to_int(row.get('fdpp_op'))
        dtrp = to_int(row.get('fdpp_dtrp'))
        ocsa = to_int(row.get('fdpp_ocsa'))
        etc = to_int(row.get('fdpp_etc'))
        
        # í™•ì •ë°œí–‰ê¸ˆì•¡ ê³„ì‚° (ë‹¨ìœ„: ì–µì›ìœ¼ë¡œ ë§ì¶¤)
        total_amt = fclt + bsninh + op + dtrp + ocsa + etc
        total_amt_uk = f"{(total_amt / 100000000):,.2f}" if total_amt > 0 else "0.00"
        
        # ê¸ˆì•¡ì´ 0ë³´ë‹¤ í° ìš©ë„ë§Œ ê³¨ë¼ì„œ ê¸€ìë¡œ ì˜ˆì˜ê²Œ ì´ì–´ë¶™ì„ (ì˜ˆ: "ì‹œì„¤, ìš´ì˜")
        purposes = []
        if fclt > 0: purposes.append("ì‹œì„¤")
        if bsninh > 0: purposes.append("ì˜ì—…ì–‘ìˆ˜")
        if op > 0: purposes.append("ìš´ì˜")
        if dtrp > 0: purposes.append("ì±„ë¬´ìƒí™˜")
        if ocsa > 0: purposes.append("íƒ€ë²•ì¸ì¦ê¶Œ")
        if etc > 0: purposes.append("ê¸°íƒ€")
        purpose_str = ", ".join(purposes)
        
        # ê³µì‹œ ì›ë¬¸ ë§í¬ ì£¼ì†Œ ë§Œë“¤ê¸°
        link = f"https://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
        
        # 7. êµ¬ê¸€ ì‹œíŠ¸ 1ì¤„(21ì¹¸) ì„¸íŒ… ì™„ë£Œ!
        new_row = [
            corp_name,                           # 1. íšŒì‚¬ëª…
            report_nm,                           # 2. ë³´ê³ ì„œëª…
            market,                              # 3. ìƒì¥ì‹œì¥
            xml_data['board_date'],              # 4. ìµœì´ˆ ì´ì‚¬íšŒê²°ì˜ì¼
            method,                              # 5. ì¦ìë°©ì‹
            product,                             # 6. ë°œí–‰ìƒí’ˆ
            new_shares_str,                      # 7. ì‹ ê·œë°œí–‰ì£¼ì‹ìˆ˜
            xml_data.get('issue_price', '-'),    # 8. í™•ì •ë°œí–‰ê°€(ì›)
            xml_data.get('base_price', '-'),     # 9. ê¸°ì¤€ì£¼ê°€
            total_amt_uk,                        # 10. í™•ì •ë°œí–‰ê¸ˆì•¡(ì–µì›)
            xml_data.get('discount', '-'),       # 11. í• ì¸(í• ì¦ë¥ )
            old_shares_str,                      # 12. ì¦ìì „ ì£¼ì‹ìˆ˜
            ratio,                               # 13. ì¦ìë¹„ìœ¨
            xml_data['pay_date'],                # 14. ë‚©ì…ì¼
            xml_data['div_date'],                # 15. ë°°ë‹¹ê¸°ì‚°ì¼
            xml_data['list_date'],               # 16. ì‹ ì£¼ì˜ ìƒì¥ ì˜ˆì •ì¼
            xml_data['board_date'],              # 17. ì´ì‚¬íšŒê²°ì˜ì¼
            purpose_str,                         # 18. ìê¸ˆìš©ë„
            xml_data['investor'],                # 19. íˆ¬ìì
            link,                                # 20. ë§í¬
            rcept_no                             # 21. ì ‘ìˆ˜ë²ˆí˜¸ (ê¸°ì¤€í‘œ)
        ]
        
        # 8. ğŸ’¡ êµ¬ê¸€ ì‹œíŠ¸ì— ë„£ê¸° (ë®ì–´ì“°ê¸° vs ìƒˆë¡œ ì¶”ê°€)
        if rcept_no in existing_rcept_nos:
            # ì‹œíŠ¸ì— ì´ë¯¸ ìˆë‹¤ë©´? ì˜ˆì „ì— í‹€ë¦¬ê±°ë‚˜ ë¹„ì–´ìˆë˜ ê°’ì¼ ìˆ˜ ìˆìœ¼ë‹ˆ 'ì™„ë²½í•œ ìµœì‹  ë°ì´í„°ë¡œ ë®ì–´ì“°ê¸°' í•©ë‹ˆë‹¤.
            row_idx = existing_rcept_nos.index(rcept_no) + 1 # ëª‡ ë²ˆì§¸ ì¤„ì¸ì§€ ì°¾ê¸° (+1ì€ ì—‘ì…€ì€ 1ì¤„ë¶€í„° ì‹œì‘í•˜ë‹ˆê¹Œ)
            try:
                worksheet.update(range_name=f'A{row_idx}:U{row_idx}', values=[new_row])
            except TypeError:
                worksheet.update(f'A{row_idx}:U{row_idx}', [new_row])
            print(f" ğŸ”„ {corp_name}: ê¸°ì¡´ ì˜¤ë¥˜ ë°ì´í„° ê²€ì¦ ë° ì™„ë²½ ë®ì–´ì“°ê¸° ì™„ë£Œ! (í–‰: {row_idx})")
            
        else:
            # ì‹œíŠ¸ì— ì—†ë‹¤ë©´? ì‹ ê·œ ë°ì´í„°ë‹ˆê¹Œ ëŒ€ê¸°ì—´ ë°”êµ¬ë‹ˆì— ì°¨ê³¡ì°¨ê³¡ ë‹´ìŠµë‹ˆë‹¤.
            print(f" ğŸ†• {corp_name}: ì‹ ê·œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ!")
            data_to_add.append(new_row)
        
    # 9. ë§ˆì§€ë§‰ ì‘ì—…: ì‹ ê·œ ëŒ€ê¸°ì—´ì— ë‹´ê¸´ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ë§¨ ë°‘ì— í•œë°©ì— ì¶”ê°€!
    if data_to_add:
        worksheet.append_rows(data_to_add)
        print(f"âœ… ìœ ìƒì¦ì: ì‹ ê·œ ê³µì‹œ {len(data_to_add)}ê±´ ì¶”ê°€ ì™„ë£Œ!")
    else:
        print("âœ… ìœ ìƒì¦ì: ìƒˆ ê³µì‹œëŠ” ì—†ìœ¼ë©°, ì™„ë²½í•œ í‘œ êµ¬ì¡° ë¶„ì„ìœ¼ë¡œ ê¸°ì¡´ ë°ì´í„° ìˆ˜ì •ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤!")

# íŒŒì´ì¬ í”„ë¡œê·¸ë¨ì´ ì‹œì‘ë˜ëŠ” ê³³
if __name__ == "__main__":
    get_and_update_yusang()
